{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Convolutional-LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls DataSet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "import requests\n",
    "from time import sleep\n",
    "import chardet\n",
    "import sys\n",
    "\n",
    "def get_file_list(root, ftype = \".csv\"):\n",
    "    import os\n",
    "    import sys\n",
    "    FileList = []\n",
    "    filename = []\n",
    "    for dirPath, dirNames, fileNames in os.walk(root):\n",
    "        for f in fileNames:\n",
    "            if f.find(ftype) > -1:\n",
    "                FileList.append(os.path.join(dirPath, f))\n",
    "                filename.append(f.replace(ftype, \"\"))\n",
    "    if len(filename) > 0:\n",
    "        a = zip(FileList, filename)\n",
    "        a = sorted(a, key = lambda t : t[1])\n",
    "        FileList, filename = zip(*a)\n",
    "    return FileList, filename\n",
    "\n",
    "def crawl3big(date_list):\n",
    "    if len(date_list) > 0:\n",
    "        with requests.Session() as s:\n",
    "            '''s.proxies = {\n",
    "              'http': 'http://172.104.89.85:8888',\n",
    "              'https': 'http://161.202.120.89:3128',\n",
    "            }'''\n",
    "            s.headers.update({'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'})\n",
    "\n",
    "            for d in date_list:\n",
    "                sys.stdout.write(\"\\rNow is fetching the data of \"+ str(d))\n",
    "                resp = s.get(\"http://www.twse.com.tw/fund/T86?response=csv&date=\"+str(d)+\"&selectType=ALL\")\n",
    "                lines = []\n",
    "                for l in resp.content.decode('big5hkscs').split(\"\\n\")[1:]:\n",
    "                    lines.append(l)\n",
    "\n",
    "                with open(\"../TBrain/DataSet/\"+str(d)+\".csv\", \"w\", encoding='big5hkscs') as f:\n",
    "                    f.writelines(lines)\n",
    "                sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x):\n",
    "    lengths2 = np.sum(np.power(x, 2))\n",
    "    lengths = np.sqrt(lengths2)\n",
    "    x = x * np.divide(lengths, (1 + lengths2))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要資料集處理 - ETF18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf18 = pd.read_csv(\"./DataSet/tetfp.csv\", encoding=\"big5hkscs\", low_memory=False)\n",
    "etf18 = etf18.rename(columns={'中文簡稱':'證券名稱'})\n",
    "etf18 = etf18.dropna(axis=1, how='all')\n",
    "etf18 = etf18.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "etf18 = etf18.drop_duplicates()\n",
    "etf18 = etf18.reset_index(drop=True)\n",
    "code_uq = list(etf18[\"代碼\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>代碼</th>\n",
       "      <th>日期</th>\n",
       "      <th>證券名稱</th>\n",
       "      <th>開盤價(元)</th>\n",
       "      <th>最高價(元)</th>\n",
       "      <th>最低價(元)</th>\n",
       "      <th>收盤價(元)</th>\n",
       "      <th>成交張數(張)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>20130102</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.65</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.40</td>\n",
       "      <td>16,487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>20130103</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.90</td>\n",
       "      <td>55.05</td>\n",
       "      <td>54.65</td>\n",
       "      <td>54.85</td>\n",
       "      <td>29,020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>20130104</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.40</td>\n",
       "      <td>54.50</td>\n",
       "      <td>9,837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>20130107</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.55</td>\n",
       "      <td>54.55</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.25</td>\n",
       "      <td>8,910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>20130108</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.20</td>\n",
       "      <td>53.65</td>\n",
       "      <td>53.90</td>\n",
       "      <td>12,507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>20130109</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>53.75</td>\n",
       "      <td>54.30</td>\n",
       "      <td>53.75</td>\n",
       "      <td>54.10</td>\n",
       "      <td>7,529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>20130110</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.30</td>\n",
       "      <td>54.65</td>\n",
       "      <td>54.15</td>\n",
       "      <td>54.50</td>\n",
       "      <td>13,953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>20130111</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.70</td>\n",
       "      <td>54.80</td>\n",
       "      <td>54.35</td>\n",
       "      <td>54.45</td>\n",
       "      <td>11,837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>20130114</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.50</td>\n",
       "      <td>53.80</td>\n",
       "      <td>54.50</td>\n",
       "      <td>7,282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>20130115</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.20</td>\n",
       "      <td>54.45</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.00</td>\n",
       "      <td>6,609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>20130116</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.05</td>\n",
       "      <td>54.05</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.70</td>\n",
       "      <td>8,142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>20130117</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.20</td>\n",
       "      <td>53.20</td>\n",
       "      <td>53.30</td>\n",
       "      <td>10,084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>20130118</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>53.95</td>\n",
       "      <td>53.95</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.95</td>\n",
       "      <td>5,410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>20130121</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>53.95</td>\n",
       "      <td>54.05</td>\n",
       "      <td>53.55</td>\n",
       "      <td>53.90</td>\n",
       "      <td>4,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>20130122</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.30</td>\n",
       "      <td>54.30</td>\n",
       "      <td>53.70</td>\n",
       "      <td>54.05</td>\n",
       "      <td>10,501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>20130123</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.20</td>\n",
       "      <td>54.30</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.00</td>\n",
       "      <td>7,266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>20130124</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>53.75</td>\n",
       "      <td>53.90</td>\n",
       "      <td>53.25</td>\n",
       "      <td>53.70</td>\n",
       "      <td>11,334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>20130125</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>53.65</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.20</td>\n",
       "      <td>53.50</td>\n",
       "      <td>8,521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>20130128</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.95</td>\n",
       "      <td>53.65</td>\n",
       "      <td>53.75</td>\n",
       "      <td>8,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>20130129</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>53.95</td>\n",
       "      <td>54.50</td>\n",
       "      <td>53.95</td>\n",
       "      <td>54.50</td>\n",
       "      <td>21,973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>20130130</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.75</td>\n",
       "      <td>54.45</td>\n",
       "      <td>54.60</td>\n",
       "      <td>21,672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>20130131</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.30</td>\n",
       "      <td>54.60</td>\n",
       "      <td>12,643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>20130201</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.70</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.80</td>\n",
       "      <td>15,057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>20130204</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.85</td>\n",
       "      <td>55.40</td>\n",
       "      <td>54.85</td>\n",
       "      <td>55.20</td>\n",
       "      <td>30,980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>20130205</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>54.90</td>\n",
       "      <td>55.10</td>\n",
       "      <td>54.90</td>\n",
       "      <td>55.00</td>\n",
       "      <td>15,988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>20130206</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>55.20</td>\n",
       "      <td>55.50</td>\n",
       "      <td>55.20</td>\n",
       "      <td>55.40</td>\n",
       "      <td>29,434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>20130218</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>55.50</td>\n",
       "      <td>55.90</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.60</td>\n",
       "      <td>29,739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>20130219</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>55.60</td>\n",
       "      <td>55.75</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>16,817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>20130220</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>55.90</td>\n",
       "      <td>56.20</td>\n",
       "      <td>55.90</td>\n",
       "      <td>56.10</td>\n",
       "      <td>21,814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>20130221</td>\n",
       "      <td>元大台灣50</td>\n",
       "      <td>55.90</td>\n",
       "      <td>56.05</td>\n",
       "      <td>55.70</td>\n",
       "      <td>55.70</td>\n",
       "      <td>9,951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19635</th>\n",
       "      <td>713</td>\n",
       "      <td>20180507</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.31</td>\n",
       "      <td>30.35</td>\n",
       "      <td>30.25</td>\n",
       "      <td>30.34</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19636</th>\n",
       "      <td>713</td>\n",
       "      <td>20180508</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.41</td>\n",
       "      <td>30.41</td>\n",
       "      <td>30.34</td>\n",
       "      <td>30.34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19637</th>\n",
       "      <td>713</td>\n",
       "      <td>20180509</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.41</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.41</td>\n",
       "      <td>30.47</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19638</th>\n",
       "      <td>713</td>\n",
       "      <td>20180510</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19639</th>\n",
       "      <td>713</td>\n",
       "      <td>20180511</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.73</td>\n",
       "      <td>30.74</td>\n",
       "      <td>30.73</td>\n",
       "      <td>30.74</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19640</th>\n",
       "      <td>713</td>\n",
       "      <td>20180514</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.78</td>\n",
       "      <td>30.85</td>\n",
       "      <td>30.78</td>\n",
       "      <td>30.85</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19641</th>\n",
       "      <td>713</td>\n",
       "      <td>20180515</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.72</td>\n",
       "      <td>30.82</td>\n",
       "      <td>30.72</td>\n",
       "      <td>30.80</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19642</th>\n",
       "      <td>713</td>\n",
       "      <td>20180516</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.73</td>\n",
       "      <td>30.82</td>\n",
       "      <td>30.73</td>\n",
       "      <td>30.80</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19643</th>\n",
       "      <td>713</td>\n",
       "      <td>20180517</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.95</td>\n",
       "      <td>30.97</td>\n",
       "      <td>30.89</td>\n",
       "      <td>30.92</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19644</th>\n",
       "      <td>713</td>\n",
       "      <td>20180518</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.95</td>\n",
       "      <td>30.96</td>\n",
       "      <td>30.92</td>\n",
       "      <td>30.96</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19645</th>\n",
       "      <td>713</td>\n",
       "      <td>20180521</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.02</td>\n",
       "      <td>31.12</td>\n",
       "      <td>31.02</td>\n",
       "      <td>31.12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19646</th>\n",
       "      <td>713</td>\n",
       "      <td>20180522</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.13</td>\n",
       "      <td>31.15</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.10</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>713</td>\n",
       "      <td>20180523</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.05</td>\n",
       "      <td>31.16</td>\n",
       "      <td>30.96</td>\n",
       "      <td>30.96</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>713</td>\n",
       "      <td>20180524</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.97</td>\n",
       "      <td>31.00</td>\n",
       "      <td>30.97</td>\n",
       "      <td>31.00</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19649</th>\n",
       "      <td>713</td>\n",
       "      <td>20180525</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.98</td>\n",
       "      <td>31.00</td>\n",
       "      <td>30.98</td>\n",
       "      <td>31.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19650</th>\n",
       "      <td>713</td>\n",
       "      <td>20180528</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.09</td>\n",
       "      <td>31.18</td>\n",
       "      <td>31.05</td>\n",
       "      <td>31.16</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19651</th>\n",
       "      <td>713</td>\n",
       "      <td>20180529</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.23</td>\n",
       "      <td>31.23</td>\n",
       "      <td>31.12</td>\n",
       "      <td>31.12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19652</th>\n",
       "      <td>713</td>\n",
       "      <td>20180530</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.95</td>\n",
       "      <td>30.95</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19653</th>\n",
       "      <td>713</td>\n",
       "      <td>20180531</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.81</td>\n",
       "      <td>30.79</td>\n",
       "      <td>30.81</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19654</th>\n",
       "      <td>713</td>\n",
       "      <td>20180601</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.90</td>\n",
       "      <td>30.96</td>\n",
       "      <td>30.90</td>\n",
       "      <td>30.96</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19655</th>\n",
       "      <td>713</td>\n",
       "      <td>20180604</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.06</td>\n",
       "      <td>31.21</td>\n",
       "      <td>31.06</td>\n",
       "      <td>31.20</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>713</td>\n",
       "      <td>20180605</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.38</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.35</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19657</th>\n",
       "      <td>713</td>\n",
       "      <td>20180606</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.39</td>\n",
       "      <td>31.46</td>\n",
       "      <td>31.36</td>\n",
       "      <td>31.45</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>713</td>\n",
       "      <td>20180607</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.52</td>\n",
       "      <td>31.52</td>\n",
       "      <td>31.36</td>\n",
       "      <td>31.39</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>713</td>\n",
       "      <td>20180608</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.39</td>\n",
       "      <td>31.43</td>\n",
       "      <td>31.30</td>\n",
       "      <td>31.30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>713</td>\n",
       "      <td>20180611</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.45</td>\n",
       "      <td>31.45</td>\n",
       "      <td>31.31</td>\n",
       "      <td>31.33</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>713</td>\n",
       "      <td>20180612</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19662</th>\n",
       "      <td>713</td>\n",
       "      <td>20180613</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.35</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.27</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663</th>\n",
       "      <td>713</td>\n",
       "      <td>20180614</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>31.22</td>\n",
       "      <td>31.22</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19664</th>\n",
       "      <td>713</td>\n",
       "      <td>20180615</td>\n",
       "      <td>元大台灣高息低波</td>\n",
       "      <td>30.94</td>\n",
       "      <td>30.95</td>\n",
       "      <td>30.82</td>\n",
       "      <td>30.84</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19665 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        代碼        日期      證券名稱  開盤價(元)  最高價(元)  最低價(元)  收盤價(元) 成交張數(張)\n",
       "0       50  20130102    元大台灣50   54.00   54.65   53.90   54.40  16,487\n",
       "1       50  20130103    元大台灣50   54.90   55.05   54.65   54.85  29,020\n",
       "2       50  20130104    元大台灣50   54.85   54.85   54.40   54.50   9,837\n",
       "3       50  20130107    元大台灣50   54.55   54.55   53.90   54.25   8,910\n",
       "4       50  20130108    元大台灣50   54.00   54.20   53.65   53.90  12,507\n",
       "5       50  20130109    元大台灣50   53.75   54.30   53.75   54.10   7,529\n",
       "6       50  20130110    元大台灣50   54.30   54.65   54.15   54.50  13,953\n",
       "7       50  20130111    元大台灣50   54.70   54.80   54.35   54.45  11,837\n",
       "8       50  20130114    元大台灣50   54.00   54.50   53.80   54.50   7,282\n",
       "9       50  20130115    元大台灣50   54.20   54.45   53.90   54.00   6,609\n",
       "10      50  20130116    元大台灣50   54.05   54.05   53.70   53.70   8,142\n",
       "11      50  20130117    元大台灣50   53.90   54.20   53.20   53.30  10,084\n",
       "12      50  20130118    元大台灣50   53.95   53.95   53.70   53.95   5,410\n",
       "13      50  20130121    元大台灣50   53.95   54.05   53.55   53.90   4,525\n",
       "14      50  20130122    元大台灣50   54.30   54.30   53.70   54.05  10,501\n",
       "15      50  20130123    元大台灣50   54.20   54.30   53.90   54.00   7,266\n",
       "16      50  20130124    元大台灣50   53.75   53.90   53.25   53.70  11,334\n",
       "17      50  20130125    元大台灣50   53.65   53.70   53.20   53.50   8,521\n",
       "18      50  20130128    元大台灣50   53.70   53.95   53.65   53.75   8,708\n",
       "19      50  20130129    元大台灣50   53.95   54.50   53.95   54.50  21,973\n",
       "20      50  20130130    元大台灣50   54.50   54.75   54.45   54.60  21,672\n",
       "21      50  20130131    元大台灣50   54.50   54.60   54.30   54.60  12,643\n",
       "22      50  20130201    元大台灣50   54.70   54.85   54.60   54.80  15,057\n",
       "23      50  20130204    元大台灣50   54.85   55.40   54.85   55.20  30,980\n",
       "24      50  20130205    元大台灣50   54.90   55.10   54.90   55.00  15,988\n",
       "25      50  20130206    元大台灣50   55.20   55.50   55.20   55.40  29,434\n",
       "26      50  20130218    元大台灣50   55.50   55.90   55.45   55.60  29,739\n",
       "27      50  20130219    元大台灣50   55.60   55.75   55.55   55.65  16,817\n",
       "28      50  20130220    元大台灣50   55.90   56.20   55.90   56.10  21,814\n",
       "29      50  20130221    元大台灣50   55.90   56.05   55.70   55.70   9,951\n",
       "...    ...       ...       ...     ...     ...     ...     ...     ...\n",
       "19635  713  20180507  元大台灣高息低波   30.31   30.35   30.25   30.34     245\n",
       "19636  713  20180508  元大台灣高息低波   30.41   30.41   30.34   30.34       7\n",
       "19637  713  20180509  元大台灣高息低波   30.41   30.47   30.41   30.47      23\n",
       "19638  713  20180510  元大台灣高息低波   30.47   30.47   30.47   30.47       1\n",
       "19639  713  20180511  元大台灣高息低波   30.73   30.74   30.73   30.74      11\n",
       "19640  713  20180514  元大台灣高息低波   30.78   30.85   30.78   30.85      38\n",
       "19641  713  20180515  元大台灣高息低波   30.72   30.82   30.72   30.80       9\n",
       "19642  713  20180516  元大台灣高息低波   30.73   30.82   30.73   30.80     116\n",
       "19643  713  20180517  元大台灣高息低波   30.95   30.97   30.89   30.92      27\n",
       "19644  713  20180518  元大台灣高息低波   30.95   30.96   30.92   30.96      11\n",
       "19645  713  20180521  元大台灣高息低波   31.02   31.12   31.02   31.12      29\n",
       "19646  713  20180522  元大台灣高息低波   31.13   31.15   31.10   31.10      32\n",
       "19647  713  20180523  元大台灣高息低波   31.05   31.16   30.96   30.96       6\n",
       "19648  713  20180524  元大台灣高息低波   30.97   31.00   30.97   31.00      26\n",
       "19649  713  20180525  元大台灣高息低波   30.98   31.00   30.98   31.00       6\n",
       "19650  713  20180528  元大台灣高息低波   31.09   31.18   31.05   31.16     214\n",
       "19651  713  20180529  元大台灣高息低波   31.23   31.23   31.12   31.12       5\n",
       "19652  713  20180530  元大台灣高息低波   30.95   30.95   30.75   30.75       4\n",
       "19653  713  20180531  元大台灣高息低波   30.80   30.81   30.79   30.81      24\n",
       "19654  713  20180601  元大台灣高息低波   30.90   30.96   30.90   30.96       8\n",
       "19655  713  20180604  元大台灣高息低波   31.06   31.21   31.06   31.20      60\n",
       "19656  713  20180605  元大台灣高息低波   31.25   31.38   31.25   31.35      48\n",
       "19657  713  20180606  元大台灣高息低波   31.39   31.46   31.36   31.45     124\n",
       "19658  713  20180607  元大台灣高息低波   31.52   31.52   31.36   31.39     123\n",
       "19659  713  20180608  元大台灣高息低波   31.39   31.43   31.30   31.30      30\n",
       "19660  713  20180611  元大台灣高息低波   31.45   31.45   31.31   31.33      10\n",
       "19661  713  20180612  元大台灣高息低波   31.25   31.25   31.25   31.25       3\n",
       "19662  713  20180613  元大台灣高息低波   31.25   31.35   31.25   31.27       8\n",
       "19663  713  20180614  元大台灣高息低波   31.22   31.22   31.00   31.00     304\n",
       "19664  713  20180615  元大台灣高息低波   30.94   30.95   30.82   30.84      33\n",
       "\n",
       "[19665 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etf18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = etf18.pop(\"代碼\").values\n",
    "op = etf18.pop(\"開盤價(元)\").values\n",
    "hi = etf18.pop(\"最高價(元)\").values\n",
    "lo = etf18.pop(\"最低價(元)\").values\n",
    "cl = etf18.pop(\"收盤價(元)\").values\n",
    "vo = etf18.pop(\"成交張數(張)\").values\n",
    "# names = list(np.unique(etf18[\"證券名稱\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(vo.shape[0]):\n",
    "    vo[i] = float(str(vo[i]).replace(\",\", \"\"))\n",
    "    cl[i] = float(str(cl[i]).replace(\",\", \"\"))\n",
    "    hi[i] = float(str(hi[i]).replace(\",\", \"\"))\n",
    "    lo[i] = float(str(lo[i]).replace(\",\", \"\"))\n",
    "    op[i] = float(str(op[i]).replace(\",\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeDF = pd.DataFrame(np.array(cl).T, columns=[\"close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_pkg = []\n",
    "hi_pkg = []\n",
    "lo_pkg = []\n",
    "cl_pkg = []\n",
    "vo_pkg = []\n",
    "date_list = list(np.unique(etf18[\"日期\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in range(1, len(code)):\n",
    "    if code[idx] != code[i]:\n",
    "        op_pkg.append(list(op[idx:i]))\n",
    "        hi_pkg.append(list(hi[idx:i]))\n",
    "        lo_pkg.append(list(lo[idx:i]))\n",
    "        cl_pkg.append(list(cl[idx:i]))\n",
    "        vo_pkg.append(list(vo[idx:i]))\n",
    "        idx = i\n",
    "\n",
    "        \n",
    "op_pkg.append(list(op[idx:len(code)]))\n",
    "hi_pkg.append(list(hi[idx:len(code)]))\n",
    "lo_pkg.append(list(lo[idx:len(code)]))\n",
    "cl_pkg.append(list(cl[idx:len(code)]))\n",
    "vo_pkg.append(list(vo[idx:len(code)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_Box = [[],[],[],[],[]]\n",
    "for idx, c in enumerate(cl_pkg):\n",
    "    for i in range(0, 5):\n",
    "        cl_Box[i] += (list(c[i+1:]) + [np.nan for x in range(min(i+1, len(c)))])\n",
    "\n",
    "clBoxDF = pd.DataFrame(np.array(cl_Box).T, columns=['cl1', 'cl2', 'cl3', 'cl4', 'cl5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeDF = pd.concat([closeDF, clBoxDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>cl1</th>\n",
       "      <th>cl2</th>\n",
       "      <th>cl3</th>\n",
       "      <th>cl4</th>\n",
       "      <th>cl5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.40</td>\n",
       "      <td>54.85</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.25</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.85</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.25</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.10</td>\n",
       "      <td>54.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.50</td>\n",
       "      <td>54.25</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.10</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.25</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.10</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.45</td>\n",
       "      <td>54.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.90</td>\n",
       "      <td>54.10</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.45</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54.10</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.45</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.50</td>\n",
       "      <td>54.45</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.45</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.30</td>\n",
       "      <td>53.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.30</td>\n",
       "      <td>53.95</td>\n",
       "      <td>53.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.30</td>\n",
       "      <td>53.95</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53.70</td>\n",
       "      <td>53.30</td>\n",
       "      <td>53.95</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.05</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53.30</td>\n",
       "      <td>53.95</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.05</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53.95</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.05</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53.90</td>\n",
       "      <td>54.05</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.50</td>\n",
       "      <td>53.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54.05</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.50</td>\n",
       "      <td>53.75</td>\n",
       "      <td>54.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54.00</td>\n",
       "      <td>53.70</td>\n",
       "      <td>53.50</td>\n",
       "      <td>53.75</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53.70</td>\n",
       "      <td>53.50</td>\n",
       "      <td>53.75</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53.50</td>\n",
       "      <td>53.75</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53.75</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.80</td>\n",
       "      <td>55.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>54.50</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.80</td>\n",
       "      <td>55.20</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>54.60</td>\n",
       "      <td>54.60</td>\n",
       "      <td>54.80</td>\n",
       "      <td>55.20</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>54.60</td>\n",
       "      <td>54.80</td>\n",
       "      <td>55.20</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54.80</td>\n",
       "      <td>55.20</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.60</td>\n",
       "      <td>55.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55.20</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.60</td>\n",
       "      <td>55.65</td>\n",
       "      <td>56.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>55.00</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.60</td>\n",
       "      <td>55.65</td>\n",
       "      <td>56.10</td>\n",
       "      <td>55.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>55.40</td>\n",
       "      <td>55.60</td>\n",
       "      <td>55.65</td>\n",
       "      <td>56.10</td>\n",
       "      <td>55.70</td>\n",
       "      <td>55.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>55.60</td>\n",
       "      <td>55.65</td>\n",
       "      <td>56.10</td>\n",
       "      <td>55.70</td>\n",
       "      <td>55.50</td>\n",
       "      <td>55.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55.65</td>\n",
       "      <td>56.10</td>\n",
       "      <td>55.70</td>\n",
       "      <td>55.50</td>\n",
       "      <td>55.80</td>\n",
       "      <td>55.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>56.10</td>\n",
       "      <td>55.70</td>\n",
       "      <td>55.50</td>\n",
       "      <td>55.80</td>\n",
       "      <td>55.70</td>\n",
       "      <td>55.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>55.70</td>\n",
       "      <td>55.50</td>\n",
       "      <td>55.80</td>\n",
       "      <td>55.70</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19635</th>\n",
       "      <td>30.34</td>\n",
       "      <td>30.34</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.74</td>\n",
       "      <td>30.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19636</th>\n",
       "      <td>30.34</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.74</td>\n",
       "      <td>30.85</td>\n",
       "      <td>30.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19637</th>\n",
       "      <td>30.47</td>\n",
       "      <td>30.47</td>\n",
       "      <td>30.74</td>\n",
       "      <td>30.85</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19638</th>\n",
       "      <td>30.47</td>\n",
       "      <td>30.74</td>\n",
       "      <td>30.85</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19639</th>\n",
       "      <td>30.74</td>\n",
       "      <td>30.85</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.92</td>\n",
       "      <td>30.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19640</th>\n",
       "      <td>30.85</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.92</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19641</th>\n",
       "      <td>30.80</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.92</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.12</td>\n",
       "      <td>31.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19642</th>\n",
       "      <td>30.80</td>\n",
       "      <td>30.92</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.12</td>\n",
       "      <td>31.10</td>\n",
       "      <td>30.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19643</th>\n",
       "      <td>30.92</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.12</td>\n",
       "      <td>31.10</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19644</th>\n",
       "      <td>30.96</td>\n",
       "      <td>31.12</td>\n",
       "      <td>31.10</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19645</th>\n",
       "      <td>31.12</td>\n",
       "      <td>31.10</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19646</th>\n",
       "      <td>31.10</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>30.96</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.12</td>\n",
       "      <td>30.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.12</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19649</th>\n",
       "      <td>31.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.12</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.81</td>\n",
       "      <td>30.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19650</th>\n",
       "      <td>31.16</td>\n",
       "      <td>31.12</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.81</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19651</th>\n",
       "      <td>31.12</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.81</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.20</td>\n",
       "      <td>31.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19652</th>\n",
       "      <td>30.75</td>\n",
       "      <td>30.81</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.20</td>\n",
       "      <td>31.35</td>\n",
       "      <td>31.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19653</th>\n",
       "      <td>30.81</td>\n",
       "      <td>30.96</td>\n",
       "      <td>31.20</td>\n",
       "      <td>31.35</td>\n",
       "      <td>31.45</td>\n",
       "      <td>31.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19654</th>\n",
       "      <td>30.96</td>\n",
       "      <td>31.20</td>\n",
       "      <td>31.35</td>\n",
       "      <td>31.45</td>\n",
       "      <td>31.39</td>\n",
       "      <td>31.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19655</th>\n",
       "      <td>31.20</td>\n",
       "      <td>31.35</td>\n",
       "      <td>31.45</td>\n",
       "      <td>31.39</td>\n",
       "      <td>31.30</td>\n",
       "      <td>31.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>31.35</td>\n",
       "      <td>31.45</td>\n",
       "      <td>31.39</td>\n",
       "      <td>31.30</td>\n",
       "      <td>31.33</td>\n",
       "      <td>31.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19657</th>\n",
       "      <td>31.45</td>\n",
       "      <td>31.39</td>\n",
       "      <td>31.30</td>\n",
       "      <td>31.33</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>31.39</td>\n",
       "      <td>31.30</td>\n",
       "      <td>31.33</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.27</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>31.30</td>\n",
       "      <td>31.33</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.27</td>\n",
       "      <td>31.00</td>\n",
       "      <td>30.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>31.33</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.27</td>\n",
       "      <td>31.00</td>\n",
       "      <td>30.84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>31.25</td>\n",
       "      <td>31.27</td>\n",
       "      <td>31.00</td>\n",
       "      <td>30.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19662</th>\n",
       "      <td>31.27</td>\n",
       "      <td>31.00</td>\n",
       "      <td>30.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19663</th>\n",
       "      <td>31.00</td>\n",
       "      <td>30.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19664</th>\n",
       "      <td>30.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19665 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       close    cl1    cl2    cl3    cl4    cl5\n",
       "0      54.40  54.85  54.50  54.25  53.90  54.10\n",
       "1      54.85  54.50  54.25  53.90  54.10  54.50\n",
       "2      54.50  54.25  53.90  54.10  54.50  54.45\n",
       "3      54.25  53.90  54.10  54.50  54.45  54.50\n",
       "4      53.90  54.10  54.50  54.45  54.50  54.00\n",
       "5      54.10  54.50  54.45  54.50  54.00  53.70\n",
       "6      54.50  54.45  54.50  54.00  53.70  53.30\n",
       "7      54.45  54.50  54.00  53.70  53.30  53.95\n",
       "8      54.50  54.00  53.70  53.30  53.95  53.90\n",
       "9      54.00  53.70  53.30  53.95  53.90  54.05\n",
       "10     53.70  53.30  53.95  53.90  54.05  54.00\n",
       "11     53.30  53.95  53.90  54.05  54.00  53.70\n",
       "12     53.95  53.90  54.05  54.00  53.70  53.50\n",
       "13     53.90  54.05  54.00  53.70  53.50  53.75\n",
       "14     54.05  54.00  53.70  53.50  53.75  54.50\n",
       "15     54.00  53.70  53.50  53.75  54.50  54.60\n",
       "16     53.70  53.50  53.75  54.50  54.60  54.60\n",
       "17     53.50  53.75  54.50  54.60  54.60  54.80\n",
       "18     53.75  54.50  54.60  54.60  54.80  55.20\n",
       "19     54.50  54.60  54.60  54.80  55.20  55.00\n",
       "20     54.60  54.60  54.80  55.20  55.00  55.40\n",
       "21     54.60  54.80  55.20  55.00  55.40  55.60\n",
       "22     54.80  55.20  55.00  55.40  55.60  55.65\n",
       "23     55.20  55.00  55.40  55.60  55.65  56.10\n",
       "24     55.00  55.40  55.60  55.65  56.10  55.70\n",
       "25     55.40  55.60  55.65  56.10  55.70  55.50\n",
       "26     55.60  55.65  56.10  55.70  55.50  55.80\n",
       "27     55.65  56.10  55.70  55.50  55.80  55.70\n",
       "28     56.10  55.70  55.50  55.80  55.70  55.10\n",
       "29     55.70  55.50  55.80  55.70  55.10  55.20\n",
       "...      ...    ...    ...    ...    ...    ...\n",
       "19635  30.34  30.34  30.47  30.47  30.74  30.85\n",
       "19636  30.34  30.47  30.47  30.74  30.85  30.80\n",
       "19637  30.47  30.47  30.74  30.85  30.80  30.80\n",
       "19638  30.47  30.74  30.85  30.80  30.80  30.92\n",
       "19639  30.74  30.85  30.80  30.80  30.92  30.96\n",
       "19640  30.85  30.80  30.80  30.92  30.96  31.12\n",
       "19641  30.80  30.80  30.92  30.96  31.12  31.10\n",
       "19642  30.80  30.92  30.96  31.12  31.10  30.96\n",
       "19643  30.92  30.96  31.12  31.10  30.96  31.00\n",
       "19644  30.96  31.12  31.10  30.96  31.00  31.00\n",
       "19645  31.12  31.10  30.96  31.00  31.00  31.16\n",
       "19646  31.10  30.96  31.00  31.00  31.16  31.12\n",
       "19647  30.96  31.00  31.00  31.16  31.12  30.75\n",
       "19648  31.00  31.00  31.16  31.12  30.75  30.81\n",
       "19649  31.00  31.16  31.12  30.75  30.81  30.96\n",
       "19650  31.16  31.12  30.75  30.81  30.96  31.20\n",
       "19651  31.12  30.75  30.81  30.96  31.20  31.35\n",
       "19652  30.75  30.81  30.96  31.20  31.35  31.45\n",
       "19653  30.81  30.96  31.20  31.35  31.45  31.39\n",
       "19654  30.96  31.20  31.35  31.45  31.39  31.30\n",
       "19655  31.20  31.35  31.45  31.39  31.30  31.33\n",
       "19656  31.35  31.45  31.39  31.30  31.33  31.25\n",
       "19657  31.45  31.39  31.30  31.33  31.25  31.27\n",
       "19658  31.39  31.30  31.33  31.25  31.27  31.00\n",
       "19659  31.30  31.33  31.25  31.27  31.00  30.84\n",
       "19660  31.33  31.25  31.27  31.00  30.84    NaN\n",
       "19661  31.25  31.27  31.00  30.84    NaN    NaN\n",
       "19662  31.27  31.00  30.84    NaN    NaN    NaN\n",
       "19663  31.00  30.84    NaN    NaN    NaN    NaN\n",
       "19664  30.84    NaN    NaN    NaN    NaN    NaN\n",
       "\n",
       "[19665 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closeDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 6201,\n",
       " 6203,\n",
       " 6204,\n",
       " 6208,\n",
       " 690,\n",
       " 692,\n",
       " 701,\n",
       " 713]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_uq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次要資料集處理 - 三大法人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬個資料\n",
    "lst = []\n",
    "flist, ftag = get_file_list(\"../TBrain/DataSet/\")\n",
    "for d in date_list:\n",
    "    if str(d) not in ftag:\n",
    "        lst.append(d)        \n",
    "if len(lst) >0:\n",
    "    crawl3big(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.twse.com.tw/fund/T86?response=csv&date=20180514&selectType=0099P\n",
    "http://www.twse.com.tw/fund/T86?response=csv&date=20180514&selectType=ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three = pd.read_csv(\"../TBrain/DataSet/\"+str(date_list[0])+\".csv\", encoding='big5hkscs')\n",
    "three.insert(0,'日期',[date_list[0] for i in three.index])\n",
    "try:\n",
    "    discrd = three.pop(\"證券代號\")\n",
    "except:\n",
    "    print(\"Error of 證券代號 on \"+str(date_list[0]))\n",
    "\n",
    "three = three.dropna(axis=1, how='all')\n",
    "three = three.dropna(axis=0,how='any')\n",
    "\n",
    "for d in date_list[1:]:\n",
    "    try:\n",
    "        a = pd.read_csv(\"./DataSet/\"+str(d)+\".csv\", encoding='big5hkscs')\n",
    "    except:\n",
    "        print(\"Error of OPEN-FILE on \"+str(d))\n",
    "        break\n",
    "        \n",
    "    a.insert(0,'日期',[d for i in a.index])\n",
    "    try:\n",
    "        discrd = a.pop(\"證券代號\")\n",
    "    except:\n",
    "        print(\"Error of 證券代號 on \"+str(d))\n",
    "        break\n",
    "        \n",
    "    a = a.dropna(axis=1, how='all')\n",
    "    a = a.dropna(axis=0,how='any')\n",
    "    pd.concat([three, a], axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "    three = three.append(a, ignore_index=True)\n",
    "    \n",
    "three = three.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "three = three.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.merge(etf18, three, on=['日期', '證券名稱'], how='left')\n",
    "res = res.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "res = res.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newVal = []\n",
    "newVal.append(res.pop(\"日期\"))\n",
    "newVal.append(res.pop(\"證券名稱\"))\n",
    "\n",
    "newDF = pd.DataFrame(np.array(newVal).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeVal = res.values\n",
    "newVal = []\n",
    "for x in threeVal:\n",
    "    x2 = []\n",
    "    for e in x:\n",
    "        x2.append(float((str(e)).replace(\",\", \"\")) / 1000)\n",
    "    newVal.append(squash(np.array(x2)))\n",
    "    \n",
    "new3DF = pd.DataFrame(newVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new3DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-proccessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDJ 指標\n",
    "\n",
    "### KDJ指標的參數設置\n",
    "\n",
    "KDJ指標參數設置的核心原則：設置參數既需要因人而異，也要因行情而異。\n",
    "在一般的分析軟體中，KDJ指標的默認參數是（9，3，3）。從實戰的角度來看，由這一參數設置而成的日K線KDJ指標存在著波動頻繁，過於靈敏，無效信號較多的缺陷，也正因為如此，KDJ指標往往被投資者所忽略，認為這一指標並沒有太大的使用價值。但事實上，如果把KDJ指標的參數進行修改，可以發現這一指標對判研價格走勢仍然具有比較好的功效。\n",
    "\n",
    "\n",
    "#### 1.以（6，3，3）為參數而設置的KDJ指標\n",
    "\n",
    "對價格波動的敏感性得到加強，它變動的頻率非常高，適合於短線投資者尋找買賣點。一般來說，KDJ三條線在超買超賣區的每一次交叉都可能成為重要的操作時點。\n",
    "#### 2.以（18，3，3）為參數設置而成的KDJ指標\n",
    "具有信號穩定而且靈敏度不低的優點，在大多數情況下都比較適用。按照這一參數設定的KDJ指標，有一條非常重要的操作原則就是：在指標處於20超賣區以下，並且指標出現底背離時，應該買進；而在80超賣區以上，指標出現頂背離時應該賣出。\n",
    "#### 3.以（24，3，3）為參數而設定的KDJ指標\n",
    "在更大程度上排除了價格波動所產生的虛假信號，用它來尋找價格的中線買點或者是中線賣點是一個比較好的選擇。\n",
    "#### 參數設置後需要注意的要點：\n",
    "##### 1.以參數（6，3，3）設置而成的KDJ指標\n",
    "由於在價格運行中會出現多次交叉，容易產生信號失真，因此需要投資者有足夠的實戰經驗，初學者一般不要輕易嘗試。\n",
    "\n",
    "##### 2.以參數（18，3，3）設置而成的KDJ指標\n",
    "在使用中必須遵循這樣的操作原則：\n",
    "(1)指標的交叉必須是出現在超賣區或者超買區時才是有效信號\n",
    "(2)在底部發出交叉時，出現兩次交叉應視為良好的買進時機\n",
    "(3)在高位出現交叉時，出現兩次交叉應視為良好的賣出時機\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDJ(high, low, close, rsv = 9, k = 3, d = 3):\n",
    "    K, D = ta.STOCH(np.array(high), np.array(low), np.array(close), fastk_period=rsv, slowk_period=k, slowk_matype=0, slowd_period=d, slowd_matype=0)\n",
    "    return K, D, (3 * D - 2 * K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = [(9,3,3), (6,3,3), (18,3,3), (24, 3, 3), (5,21,11)]\n",
    "kdj = pd.DataFrame()\n",
    "for hi, lo, cl in zip(hi_pkg, lo_pkg, cl_pkg):\n",
    "    box = []\n",
    "    for p in paras:\n",
    "        k, d, j = KDJ(hi, lo, cl, p[0], p[1], p[2])\n",
    "        box.append(k)\n",
    "        box.append(d)\n",
    "        box.append(j)\n",
    "    kdj = kdj.append(pd.DataFrame(data=np.array(box).T), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PriceLoc(close, high, low, period = [6, 11, 22, 43, 65, 130]):\n",
    "    close = np.array(close)\n",
    "    high = np.array(high)\n",
    "    low = np.array(low)\n",
    "    WCP = ta.WCLPRICE(high, low, close)\n",
    "    \n",
    "    sma_cl = []\n",
    "    for p in period:\n",
    "        sma_cl.append(ta.SMA(close, timeperiod=p))\n",
    "    sma_wcl = []\n",
    "    for p in period:\n",
    "        sma_wcl.append(ta.SMA(WCP, timeperiod=p))\n",
    "    \n",
    "    period.reverse()\n",
    "    period_r = np.array([period])\n",
    "    \n",
    "    wsma_cl = np.sum(period_r.T * sma_cl, axis=0) / sum(period)\n",
    "    wsma_wcl = np.sum(period_r.T * sma_wcl, axis=0) / sum(period)\n",
    "    \n",
    "    space = []\n",
    "    space.append((WCP - wsma_cl) / wsma_cl)\n",
    "    space.append((WCP - wsma_wcl) / wsma_wcl)\n",
    "    for i in range(len(sma_cl)):\n",
    "        space.append((WCP - sma_cl[i]) / sma_cl[i])\n",
    "    for i in range(len(sma_wcl)):\n",
    "        space.append((WCP - sma_wcl[i]) / sma_wcl[i])\n",
    "        \n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VolLoc(volume, period = [6, 11, 22, 43, 65, 130]):\n",
    "    volume = np.array(volume)\n",
    "    \n",
    "    smv = []\n",
    "    for p in period:\n",
    "        smv.append(ta.SMA(volume, timeperiod=p))\n",
    "    \n",
    "    period.reverse()\n",
    "    period_r = np.array([period])\n",
    "    \n",
    "    wsmv = np.sum(period_r.T * smv, axis=0) / sum(period)\n",
    "    \n",
    "    space = []\n",
    "    space.append((volume - wsmv) / wsmv)\n",
    "    for i in range(len(smv)):\n",
    "        space.append((volume - smv[i]) / smv[i])\n",
    "    \n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StockLoc(close, high, low, volume, period = [6, 11, 22, 43, 65]):\n",
    "    return PriceLoc(close, high, low, period) + VolLoc(volume, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = []\n",
    "for i in range(len(cl_pkg)):\n",
    "    db.append(StockLoc(cl_pkg[i], hi_pkg[i], lo_pkg[i], vo_pkg[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = pd.DataFrame()\n",
    "for d in db:\n",
    "    loc = loc.append(pd.DataFrame(data=np.array(d).T), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClosePercenting(close, period = [1, 2, 3, 4, 5]):\n",
    "    period.sort()\n",
    "    cp = []\n",
    "    for p in period:\n",
    "        cp.append([])\n",
    "        \n",
    "    for i in range(len(close) - period[-1]):\n",
    "        for j, p in zip(range(len(period)), period):\n",
    "            cp[j].append((close[i + p] - close[i]) / close[i] * 100)\n",
    "            \n",
    "    for i in range(period[-1]):\n",
    "        for j in range(len(period)):\n",
    "            cp[j].append(np.nan)\n",
    "    \n",
    "    data_dict = {}\n",
    "    for j in range(len(period)):\n",
    "        data_dict.update({\"change%_D\"+str(period[j]) : cp[j]})\n",
    "    \n",
    "    out = pd.DataFrame(data=data_dict)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change = ClosePercenting(cl_pkg[0])\n",
    "for cl in cl_pkg[1:]:\n",
    "    change = change.append(ClosePercenting(cl), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Recognition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [ta.CDL2CROWS, ta.CDL3BLACKCROWS, ta.CDL3INSIDE, ta.CDL3LINESTRIKE, ta.CDL3OUTSIDE, ta.CDL3WHITESOLDIERS, ta.CDLABANDONEDBABY, ta.CDLADVANCEBLOCK, ta.CDLBELTHOLD, ta.CDLBREAKAWAY, ta.CDLCLOSINGMARUBOZU, ta.CDLCONCEALBABYSWALL, ta.CDLCOUNTERATTACK, ta.CDLDARKCLOUDCOVER, ta.CDLDOJI, ta.CDLDOJISTAR, ta.CDLDRAGONFLYDOJI, ta.CDLENGULFING, ta.CDLEVENINGDOJISTAR, ta.CDLEVENINGSTAR, ta.CDLGAPSIDESIDEWHITE, ta.CDLGRAVESTONEDOJI, ta.CDLHANGINGMAN, ta.CDLHARAMI, ta.CDLHARAMICROSS, ta.CDLHIGHWAVE, ta.CDLHIKKAKE, ta.CDLHIKKAKEMOD, ta.CDLHOMINGPIGEON, ta.CDLIDENTICAL3CROWS, ta.CDLINNECK, ta.CDLINVERTEDHAMMER, ta.CDLKICKING, ta.CDLKICKINGBYLENGTH, ta.CDLLADDERBOTTOM, ta.CDLLONGLEGGEDDOJI, ta.CDLLONGLINE, ta.CDLMARUBOZU, ta.CDLMATCHINGLOW, ta.CDLMATHOLD, ta.CDLMORNINGDOJISTAR, ta.CDLMORNINGSTAR, ta.CDLONNECK, ta.CDLPIERCING, ta.CDLRICKSHAWMAN, ta.CDLRISEFALL3METHODS, ta.CDLSEPARATINGLINES, ta.CDLSHOOTINGSTAR, ta.CDLSHORTLINE, ta.CDLSPINNINGTOP, ta.CDLSTALLEDPATTERN, ta.CDLSTICKSANDWICH, ta.CDLTAKURI, ta.CDLTASUKIGAP, ta.CDLTHRUSTING, ta.CDLTRISTAR, ta.CDLUNIQUE3RIVER, ta.CDLUPSIDEGAP2CROWS, ta.CDLXSIDEGAP3METHODS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptnDF = pd.DataFrame()\n",
    "for i in range(len(code_uq)):\n",
    "    a = []\n",
    "    for f in func_list:\n",
    "        a.append(f(np.array(op_pkg[i]), np.array(hi_pkg[i]), np.array(lo_pkg[i]), np.array(cl_pkg[i])))\n",
    "\n",
    "    ptnDF = ptnDF.append(pd.DataFrame(np.array(a).T), ignore_index=True) \n",
    "    \n",
    "ptnVal = ptnDF.values\n",
    "ptnValSQ = []\n",
    "for x in ptnVal:\n",
    "    ptnValSQ.append(squash(x))\n",
    "\n",
    "ptnDFSQ = pd.DataFrame(ptnValSQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptnDFSQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalETF18 = pd.concat([etf18, change, closeDF, loc, kdj, new3DF, ptnDFSQ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalETF18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalETF18.to_csv(\"../TBrain/DataSet/final18_\"+str(date_list[-1])+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalETF18 = pd.read_csv(\"../TBrain/DataSet/final18_\"+str(date_list[-1])+\".csv\")\n",
    "finalETF18 = finalETF18.dropna() # 去除空資訊\n",
    "finalETF18 = finalETF18.drop_duplicates()\n",
    "discard = finalETF18.pop(\"日期\")# 移除日期\n",
    "tags = finalETF18.pop(\"證券名稱\").values # 取得標籤\n",
    "dataVal = finalETF18.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataValSplit = []\n",
    "\n",
    "idx = 0\n",
    "for i in range(1, len(tags)):\n",
    "    if tags[idx] != tags[i]:\n",
    "        dataValSplit.append(list(dataVal[idx:i]))\n",
    "        idx = i\n",
    "\n",
    "dataValSplit.append(list(dataVal[idx:len(dataVal) - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for d in dataValSplit:\n",
    "    frames.append(pd.DataFrame(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.092764</td>\n",
       "      <td>2.875696</td>\n",
       "      <td>2.782931</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.90</td>\n",
       "      <td>53.85</td>\n",
       "      <td>55.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.185185</td>\n",
       "      <td>-0.277778</td>\n",
       "      <td>2.685185</td>\n",
       "      <td>2.592593</td>\n",
       "      <td>2.037037</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.90</td>\n",
       "      <td>53.85</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.577331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.092764</td>\n",
       "      <td>2.875696</td>\n",
       "      <td>2.782931</td>\n",
       "      <td>2.226345</td>\n",
       "      <td>3.061224</td>\n",
       "      <td>53.90</td>\n",
       "      <td>53.85</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.971216</td>\n",
       "      <td>2.878366</td>\n",
       "      <td>2.321263</td>\n",
       "      <td>3.156917</td>\n",
       "      <td>3.342618</td>\n",
       "      <td>53.85</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.090171</td>\n",
       "      <td>-0.631199</td>\n",
       "      <td>0.180343</td>\n",
       "      <td>0.360685</td>\n",
       "      <td>0.721371</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.541516</td>\n",
       "      <td>0.270758</td>\n",
       "      <td>0.451264</td>\n",
       "      <td>0.812274</td>\n",
       "      <td>0.722022</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.816697</td>\n",
       "      <td>0.998185</td>\n",
       "      <td>1.361162</td>\n",
       "      <td>1.270417</td>\n",
       "      <td>2.359347</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.540054</td>\n",
       "      <td>0.450045</td>\n",
       "      <td>1.530153</td>\n",
       "      <td>1.800180</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.359389</td>\n",
       "      <td>0.269542</td>\n",
       "      <td>1.347709</td>\n",
       "      <td>1.617251</td>\n",
       "      <td>1.796945</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.089526</td>\n",
       "      <td>0.984781</td>\n",
       "      <td>1.253357</td>\n",
       "      <td>1.432408</td>\n",
       "      <td>1.880036</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.075269</td>\n",
       "      <td>1.344086</td>\n",
       "      <td>1.523297</td>\n",
       "      <td>1.971326</td>\n",
       "      <td>2.329749</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.443262</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>1.241135</td>\n",
       "      <td>2.570922</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.176835</td>\n",
       "      <td>0.618921</td>\n",
       "      <td>0.972591</td>\n",
       "      <td>2.298851</td>\n",
       "      <td>2.917772</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.441306</td>\n",
       "      <td>0.794351</td>\n",
       "      <td>2.118270</td>\n",
       "      <td>2.736099</td>\n",
       "      <td>2.206531</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.351494</td>\n",
       "      <td>1.669596</td>\n",
       "      <td>2.284710</td>\n",
       "      <td>1.757469</td>\n",
       "      <td>1.493849</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.313485</td>\n",
       "      <td>1.926445</td>\n",
       "      <td>1.401051</td>\n",
       "      <td>1.138354</td>\n",
       "      <td>1.401051</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.605013</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>-0.172861</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>0.172861</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.515464</td>\n",
       "      <td>-0.773196</td>\n",
       "      <td>-0.515464</td>\n",
       "      <td>-0.429553</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.259067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086356</td>\n",
       "      <td>1.381693</td>\n",
       "      <td>0.863558</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.346320</td>\n",
       "      <td>1.645022</td>\n",
       "      <td>1.125541</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.086356</td>\n",
       "      <td>1.381693</td>\n",
       "      <td>0.863558</td>\n",
       "      <td>0.690846</td>\n",
       "      <td>0.690846</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.294219</td>\n",
       "      <td>0.776531</td>\n",
       "      <td>0.603969</td>\n",
       "      <td>0.603969</td>\n",
       "      <td>0.517688</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.511073</td>\n",
       "      <td>-0.681431</td>\n",
       "      <td>-0.681431</td>\n",
       "      <td>-0.766610</td>\n",
       "      <td>-2.896082</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.171233</td>\n",
       "      <td>-0.171233</td>\n",
       "      <td>-0.256849</td>\n",
       "      <td>-2.397260</td>\n",
       "      <td>-2.654110</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.085763</td>\n",
       "      <td>-2.229846</td>\n",
       "      <td>-2.487136</td>\n",
       "      <td>-1.629503</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.085763</td>\n",
       "      <td>-2.229846</td>\n",
       "      <td>-2.487136</td>\n",
       "      <td>-1.629503</td>\n",
       "      <td>-1.972556</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-2.145923</td>\n",
       "      <td>-2.403433</td>\n",
       "      <td>-1.545064</td>\n",
       "      <td>-1.888412</td>\n",
       "      <td>-1.030043</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.263158</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>1.140351</td>\n",
       "      <td>-0.087719</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "      <td>57.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.879507</td>\n",
       "      <td>0.527704</td>\n",
       "      <td>1.407212</td>\n",
       "      <td>0.175901</td>\n",
       "      <td>0.175901</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "      <td>57.65</td>\n",
       "      <td>56.95</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.348736</td>\n",
       "      <td>0.523104</td>\n",
       "      <td>-0.697472</td>\n",
       "      <td>-0.697472</td>\n",
       "      <td>-1.133391</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "      <td>57.65</td>\n",
       "      <td>56.95</td>\n",
       "      <td>56.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1.010101</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>-0.820707</td>\n",
       "      <td>-0.315657</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>79.20</td>\n",
       "      <td>80.00</td>\n",
       "      <td>79.40</td>\n",
       "      <td>78.55</td>\n",
       "      <td>78.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>-1.312500</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.00</td>\n",
       "      <td>79.40</td>\n",
       "      <td>78.55</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>-1.070529</td>\n",
       "      <td>-0.566751</td>\n",
       "      <td>0.125945</td>\n",
       "      <td>0.755668</td>\n",
       "      <td>1.322418</td>\n",
       "      <td>79.40</td>\n",
       "      <td>78.55</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>0.509230</td>\n",
       "      <td>1.209421</td>\n",
       "      <td>1.845958</td>\n",
       "      <td>2.418842</td>\n",
       "      <td>2.673456</td>\n",
       "      <td>78.55</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>0.696643</td>\n",
       "      <td>1.329956</td>\n",
       "      <td>1.899937</td>\n",
       "      <td>2.153262</td>\n",
       "      <td>3.356555</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>0.628931</td>\n",
       "      <td>1.194969</td>\n",
       "      <td>1.446541</td>\n",
       "      <td>2.641509</td>\n",
       "      <td>3.773585</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>0.248602</td>\n",
       "      <td>1.429459</td>\n",
       "      <td>2.548167</td>\n",
       "      <td>1.491610</td>\n",
       "      <td>1.615911</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1.177929</td>\n",
       "      <td>2.293862</td>\n",
       "      <td>1.239926</td>\n",
       "      <td>1.363918</td>\n",
       "      <td>0.681959</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1.102941</td>\n",
       "      <td>0.061275</td>\n",
       "      <td>0.183824</td>\n",
       "      <td>-0.490196</td>\n",
       "      <td>-0.796569</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>-1.030303</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>-1.575758</td>\n",
       "      <td>-1.878788</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>0.122474</td>\n",
       "      <td>-0.551133</td>\n",
       "      <td>-0.857318</td>\n",
       "      <td>0.489896</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>-0.672783</td>\n",
       "      <td>-0.978593</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.489297</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.707071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>-0.307882</td>\n",
       "      <td>1.046798</td>\n",
       "      <td>0.677340</td>\n",
       "      <td>0.184729</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>1.358863</td>\n",
       "      <td>0.988264</td>\n",
       "      <td>0.494132</td>\n",
       "      <td>0.741198</td>\n",
       "      <td>1.111797</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>-0.365631</td>\n",
       "      <td>-0.853138</td>\n",
       "      <td>-0.609385</td>\n",
       "      <td>-0.243754</td>\n",
       "      <td>0.182815</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>-0.489297</td>\n",
       "      <td>-0.244648</td>\n",
       "      <td>0.122324</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.122324</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0.245851</td>\n",
       "      <td>0.614628</td>\n",
       "      <td>1.044868</td>\n",
       "      <td>0.614628</td>\n",
       "      <td>-1.167793</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>0.367872</td>\n",
       "      <td>0.797057</td>\n",
       "      <td>0.367872</td>\n",
       "      <td>-1.410178</td>\n",
       "      <td>-0.980993</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>0.427611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.771533</td>\n",
       "      <td>-1.343922</td>\n",
       "      <td>-0.610874</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>-0.425791</td>\n",
       "      <td>-2.189781</td>\n",
       "      <td>-1.763990</td>\n",
       "      <td>-1.034063</td>\n",
       "      <td>0.486618</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>-1.771533</td>\n",
       "      <td>-1.343922</td>\n",
       "      <td>-0.610874</td>\n",
       "      <td>0.916310</td>\n",
       "      <td>0.794136</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0.435323</td>\n",
       "      <td>1.181592</td>\n",
       "      <td>2.736318</td>\n",
       "      <td>2.611940</td>\n",
       "      <td>3.606965</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>0.743034</td>\n",
       "      <td>2.291022</td>\n",
       "      <td>2.167183</td>\n",
       "      <td>3.157895</td>\n",
       "      <td>3.343653</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>1.536570</td>\n",
       "      <td>1.413645</td>\n",
       "      <td>2.397050</td>\n",
       "      <td>2.581438</td>\n",
       "      <td>1.475108</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>-0.121065</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>1.029056</td>\n",
       "      <td>-0.060533</td>\n",
       "      <td>0.060533</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>0.180072</td>\n",
       "      <td>-0.900360</td>\n",
       "      <td>-0.780312</td>\n",
       "      <td>-0.960384</td>\n",
       "      <td>-0.360144</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>-1.078490</td>\n",
       "      <td>-0.958658</td>\n",
       "      <td>-1.138406</td>\n",
       "      <td>-0.539245</td>\n",
       "      <td>-2.037148</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.121139</td>\n",
       "      <td>-0.060569</td>\n",
       "      <td>0.545124</td>\n",
       "      <td>-0.969110</td>\n",
       "      <td>-0.726832</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.00</td>\n",
       "      <td>81.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1268 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4      5      6      7    \\\n",
       "0     0.185529  0.000000 -0.092764  2.875696  2.782931  53.90  54.00  53.90   \n",
       "1    -0.185185 -0.277778  2.685185  2.592593  2.037037  54.00  53.90  53.85   \n",
       "2    -0.092764  2.875696  2.782931  2.226345  3.061224  53.90  53.85  55.45   \n",
       "3     2.971216  2.878366  2.321263  3.156917  3.342618  53.85  55.45  55.40   \n",
       "4    -0.090171 -0.631199  0.180343  0.360685  0.721371  55.45  55.40  55.10   \n",
       "5    -0.541516  0.270758  0.451264  0.812274  0.722022  55.40  55.10  55.55   \n",
       "6     0.816697  0.998185  1.361162  1.270417  2.359347  55.10  55.55  55.65   \n",
       "7     0.180018  0.540054  0.450045  1.530153  1.800180  55.55  55.65  55.85   \n",
       "8     0.359389  0.269542  1.347709  1.617251  1.796945  55.65  55.85  55.80   \n",
       "9    -0.089526  0.984781  1.253357  1.432408  1.880036  55.85  55.80  56.40   \n",
       "10    1.075269  1.344086  1.523297  1.971326  2.329749  55.80  56.40  56.55   \n",
       "11    0.265957  0.443262  0.886525  1.241135  2.570922  56.40  56.55  56.65   \n",
       "12    0.176835  0.618921  0.972591  2.298851  2.917772  56.55  56.65  56.90   \n",
       "13    0.441306  0.794351  2.118270  2.736099  2.206531  56.65  56.90  57.10   \n",
       "14    0.351494  1.669596  2.284710  1.757469  1.493849  56.90  57.10  57.85   \n",
       "15    1.313485  1.926445  1.401051  1.138354  1.401051  57.10  57.85  58.20   \n",
       "16    0.605013  0.086430 -0.172861  0.086430  0.172861  57.85  58.20  57.90   \n",
       "17   -0.515464 -0.773196 -0.515464 -0.429553  0.859107  58.20  57.90  57.75   \n",
       "18   -0.259067  0.000000  0.086356  1.381693  0.863558  57.90  57.75  57.90   \n",
       "19    0.259740  0.346320  1.645022  1.125541  0.952381  57.75  57.90  57.95   \n",
       "20    0.086356  1.381693  0.863558  0.690846  0.690846  57.90  57.95  58.70   \n",
       "21    1.294219  0.776531  0.603969  0.603969  0.517688  57.95  58.70  58.40   \n",
       "22   -0.511073 -0.681431 -0.681431 -0.766610 -2.896082  58.70  58.40  58.30   \n",
       "23   -0.171233 -0.171233 -0.256849 -2.397260 -2.654110  58.40  58.30  58.30   \n",
       "24    0.000000 -0.085763 -2.229846 -2.487136 -1.629503  58.30  58.30  58.25   \n",
       "25   -0.085763 -2.229846 -2.487136 -1.629503 -1.972556  58.30  58.25  57.00   \n",
       "26   -2.145923 -2.403433 -1.545064 -1.888412 -1.030043  58.25  57.00  56.85   \n",
       "27   -0.263158  0.614035  0.263158  1.140351 -0.087719  57.00  56.85  57.35   \n",
       "28    0.879507  0.527704  1.407212  0.175901  0.175901  56.85  57.35  57.15   \n",
       "29   -0.348736  0.523104 -0.697472 -0.697472 -1.133391  57.35  57.15  57.65   \n",
       "...        ...       ...       ...       ...       ...    ...    ...    ...   \n",
       "1238  1.010101  0.252525 -0.820707 -0.315657  0.378788  79.20  80.00  79.40   \n",
       "1239 -0.750000 -1.812500 -1.312500 -0.625000  0.000000  80.00  79.40  78.55   \n",
       "1240 -1.070529 -0.566751  0.125945  0.755668  1.322418  79.40  78.55  78.95   \n",
       "1241  0.509230  1.209421  1.845958  2.418842  2.673456  78.55  78.95  79.50   \n",
       "1242  0.696643  1.329956  1.899937  2.153262  3.356555  78.95  79.50  80.00   \n",
       "1243  0.628931  1.194969  1.446541  2.641509  3.773585  79.50  80.00  80.45   \n",
       "1244  0.562500  0.812500  2.000000  3.125000  2.062500  80.00  80.45  80.65   \n",
       "1245  0.248602  1.429459  2.548167  1.491610  1.615911  80.45  80.65  81.60   \n",
       "1246  1.177929  2.293862  1.239926  1.363918  0.681959  80.65  81.60  82.50   \n",
       "1247  1.102941  0.061275  0.183824 -0.490196 -0.796569  81.60  82.50  81.65   \n",
       "1248 -1.030303 -0.909091 -1.575758 -1.878788 -0.545455  82.50  81.65  81.75   \n",
       "1249  0.122474 -0.551133 -0.857318  0.489896  0.122474  81.65  81.75  81.20   \n",
       "1250 -0.672783 -0.978593  0.366972  0.000000 -0.489297  81.75  81.20  80.95   \n",
       "1251 -0.307882  1.046798  0.677340  0.184729  0.431034  81.20  80.95  82.05   \n",
       "1252  1.358863  0.988264  0.494132  0.741198  1.111797  80.95  82.05  81.75   \n",
       "1253 -0.365631 -0.853138 -0.609385 -0.243754  0.182815  82.05  81.75  81.35   \n",
       "1254 -0.489297 -0.244648  0.122324  0.550459  0.122324  81.75  81.35  81.55   \n",
       "1255  0.245851  0.614628  1.044868  0.614628 -1.167793  81.35  81.55  81.85   \n",
       "1256  0.367872  0.797057  0.367872 -1.410178 -0.980993  81.55  81.85  82.20   \n",
       "1257  0.427611  0.000000 -1.771533 -1.343922 -0.610874  81.85  82.20  81.85   \n",
       "1258 -0.425791 -2.189781 -1.763990 -1.034063  0.486618  82.20  81.85  80.40   \n",
       "1259 -1.771533 -1.343922 -0.610874  0.916310  0.794136  81.85  80.40  80.75   \n",
       "1260  0.435323  1.181592  2.736318  2.611940  3.606965  80.40  80.75  81.35   \n",
       "1261  0.743034  2.291022  2.167183  3.157895  3.343653  80.75  81.35  82.60   \n",
       "1262  1.536570  1.413645  2.397050  2.581438  1.475108  81.35  82.60  82.50   \n",
       "1263 -0.121065  0.847458  1.029056 -0.060533  0.060533  82.60  82.50  83.30   \n",
       "1264  0.969697  1.151515  0.060606  0.181818  0.000000  82.50  83.30  83.45   \n",
       "1265  0.180072 -0.900360 -0.780312 -0.960384 -0.360144  83.30  83.45  82.55   \n",
       "1266 -1.078490 -0.958658 -1.138406 -0.539245 -2.037148  83.45  82.55  82.65   \n",
       "1267  0.121139 -0.060569  0.545124 -0.969110 -0.726832  82.55  82.65  82.50   \n",
       "\n",
       "        8      9   ...        115  116  117       118       119       120  \\\n",
       "0     53.85  55.45 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1     55.45  55.40 ...   0.000000  0.0  0.0  0.000000  0.000000 -0.577331   \n",
       "2     55.40  55.10 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "3     55.10  55.55 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "4     55.55  55.65 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "5     55.65  55.85 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "6     55.85  55.80 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "7     55.80  56.40 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "8     56.40  56.55 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "9     56.55  56.65 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "10    56.65  56.90 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "11    56.90  57.10 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "12    57.10  57.85 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "13    57.85  58.20 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "14    58.20  57.90 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "15    57.90  57.75 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "16    57.75  57.90 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "17    57.90  57.95 ...   0.447205  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "18    57.95  58.70 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "19    58.70  58.40 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "20    58.40  58.30 ...  -0.999900  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "21    58.30  58.30 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "22    58.30  58.25 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "23    58.25  57.00 ...   0.000000  0.0  0.0  0.000000  0.577331  0.000000   \n",
       "24    57.00  56.85 ...   0.408241  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "25    56.85  57.35 ...  -0.707071  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "26    57.35  57.15 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "27    57.15  57.65 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "28    57.65  56.95 ...  -0.999900  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "29    56.95  56.95 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "...     ...    ... ...        ...  ...  ...       ...       ...       ...   \n",
       "1238  78.55  78.95 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1239  78.95  79.50 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1240  79.50  80.00 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1241  80.00  80.45 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1242  80.45  80.65 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1243  80.65  81.60 ...   0.353549  0.0  0.0  0.353549  0.000000  0.000000   \n",
       "1244  81.60  82.50 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1245  82.50  81.65 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1246  81.65  81.75 ...   0.000000  0.0  0.0  0.408241  0.000000  0.000000   \n",
       "1247  81.75  81.20 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1248  81.20  80.95 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1249  80.95  82.05 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1250  82.05  81.75 ...   0.000000  0.0  0.0  0.000000  0.000000 -0.707071   \n",
       "1251  81.75  81.35 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1252  81.35  81.55 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1253  81.55  81.85 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1254  81.85  82.20 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1255  82.20  81.85 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1256  81.85  80.40 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1257  80.40  80.75 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1258  80.75  81.35 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1259  81.35  82.60 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1260  82.60  82.50 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1261  82.50  83.30 ...  -0.353549  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1262  83.30  83.45 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1263  83.45  82.55 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1264  82.55  82.65 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1265  82.65  82.50 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1266  82.50  83.00 ...  -0.499988  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "1267  83.00  81.75 ...   0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "      121  122  123  124  \n",
       "0     0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  \n",
       "5     0.0  0.0  0.0  0.0  \n",
       "6     0.0  0.0  0.0  0.0  \n",
       "7     0.0  0.0  0.0  0.0  \n",
       "8     0.0  0.0  0.0  0.0  \n",
       "9     0.0  0.0  0.0  0.0  \n",
       "10    0.0  0.0  0.0  0.0  \n",
       "11    0.0  0.0  0.0  0.0  \n",
       "12    0.0  0.0  0.0  0.0  \n",
       "13    0.0  0.0  0.0  0.0  \n",
       "14    0.0  0.0  0.0  0.0  \n",
       "15    0.0  0.0  0.0  0.0  \n",
       "16    0.0  0.0  0.0  0.0  \n",
       "17    0.0  0.0  0.0  0.0  \n",
       "18    0.0  0.0  0.0  0.0  \n",
       "19    0.0  0.0  0.0  0.0  \n",
       "20    0.0  0.0  0.0  0.0  \n",
       "21    0.0  0.0  0.0  0.0  \n",
       "22    0.0  0.0  0.0  0.0  \n",
       "23    0.0  0.0  0.0  0.0  \n",
       "24    0.0  0.0  0.0  0.0  \n",
       "25    0.0  0.0  0.0  0.0  \n",
       "26    0.0  0.0  0.0  0.0  \n",
       "27    0.0  0.0  0.0  0.0  \n",
       "28    0.0  0.0  0.0  0.0  \n",
       "29    0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  \n",
       "1238  0.0  0.0  0.0  0.0  \n",
       "1239  0.0  0.0  0.0  0.0  \n",
       "1240  0.0  0.0  0.0  0.0  \n",
       "1241  0.0  0.0  0.0  0.0  \n",
       "1242  0.0  0.0  0.0  0.0  \n",
       "1243  0.0  0.0  0.0  0.0  \n",
       "1244  0.0  0.0  0.0  0.0  \n",
       "1245  0.0  0.0  0.0  0.0  \n",
       "1246  0.0  0.0  0.0  0.0  \n",
       "1247  0.0  0.0  0.0  0.0  \n",
       "1248  0.0  0.0  0.0  0.0  \n",
       "1249  0.0  0.0  0.0  0.0  \n",
       "1250  0.0  0.0  0.0  0.0  \n",
       "1251  0.0  0.0  0.0  0.0  \n",
       "1252  0.0  0.0  0.0  0.0  \n",
       "1253  0.0  0.0  0.0  0.0  \n",
       "1254  0.0  0.0  0.0  0.0  \n",
       "1255  0.0  0.0  0.0  0.0  \n",
       "1256  0.0  0.0  0.0  0.0  \n",
       "1257  0.0  0.0  0.0  0.0  \n",
       "1258  0.0  0.0  0.0  0.0  \n",
       "1259  0.0  0.0  0.0  0.0  \n",
       "1260  0.0  0.0  0.0  0.0  \n",
       "1261  0.0  0.0  0.0  0.0  \n",
       "1262  0.0  0.0  0.0  0.0  \n",
       "1263  0.0  0.0  0.0  0.0  \n",
       "1264  0.0  0.0  0.0  0.0  \n",
       "1265  0.0  0.0  0.0  0.0  \n",
       "1266  0.0  0.0  0.0  0.0  \n",
       "1267  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1268 rows x 125 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_box = []\n",
    "for f in frames:\n",
    "    tmp = []\n",
    "    for i in range(0, 11):\n",
    "        tmp.append(f.pop(i).values)\n",
    "    Y_box.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_frames = []\n",
    "for y in Y_box:\n",
    "    Y_frames.append(pd.DataFrame(np.array(y).T, columns=['d1', 'd2', 'd3', 'd4', 'd5', 'close', 'cl1', 'cl2', 'cl3', 'cl4', 'cl5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>close</th>\n",
       "      <th>cl1</th>\n",
       "      <th>cl2</th>\n",
       "      <th>cl3</th>\n",
       "      <th>cl4</th>\n",
       "      <th>cl5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.092764</td>\n",
       "      <td>2.875696</td>\n",
       "      <td>2.782931</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.90</td>\n",
       "      <td>53.85</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.185185</td>\n",
       "      <td>-0.277778</td>\n",
       "      <td>2.685185</td>\n",
       "      <td>2.592593</td>\n",
       "      <td>2.037037</td>\n",
       "      <td>54.00</td>\n",
       "      <td>53.90</td>\n",
       "      <td>53.85</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.092764</td>\n",
       "      <td>2.875696</td>\n",
       "      <td>2.782931</td>\n",
       "      <td>2.226345</td>\n",
       "      <td>3.061224</td>\n",
       "      <td>53.90</td>\n",
       "      <td>53.85</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.971216</td>\n",
       "      <td>2.878366</td>\n",
       "      <td>2.321263</td>\n",
       "      <td>3.156917</td>\n",
       "      <td>3.342618</td>\n",
       "      <td>53.85</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.090171</td>\n",
       "      <td>-0.631199</td>\n",
       "      <td>0.180343</td>\n",
       "      <td>0.360685</td>\n",
       "      <td>0.721371</td>\n",
       "      <td>55.45</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.541516</td>\n",
       "      <td>0.270758</td>\n",
       "      <td>0.451264</td>\n",
       "      <td>0.812274</td>\n",
       "      <td>0.722022</td>\n",
       "      <td>55.40</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.816697</td>\n",
       "      <td>0.998185</td>\n",
       "      <td>1.361162</td>\n",
       "      <td>1.270417</td>\n",
       "      <td>2.359347</td>\n",
       "      <td>55.10</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.540054</td>\n",
       "      <td>0.450045</td>\n",
       "      <td>1.530153</td>\n",
       "      <td>1.800180</td>\n",
       "      <td>55.55</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.359389</td>\n",
       "      <td>0.269542</td>\n",
       "      <td>1.347709</td>\n",
       "      <td>1.617251</td>\n",
       "      <td>1.796945</td>\n",
       "      <td>55.65</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.089526</td>\n",
       "      <td>0.984781</td>\n",
       "      <td>1.253357</td>\n",
       "      <td>1.432408</td>\n",
       "      <td>1.880036</td>\n",
       "      <td>55.85</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.075269</td>\n",
       "      <td>1.344086</td>\n",
       "      <td>1.523297</td>\n",
       "      <td>1.971326</td>\n",
       "      <td>2.329749</td>\n",
       "      <td>55.80</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.443262</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>1.241135</td>\n",
       "      <td>2.570922</td>\n",
       "      <td>56.40</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.176835</td>\n",
       "      <td>0.618921</td>\n",
       "      <td>0.972591</td>\n",
       "      <td>2.298851</td>\n",
       "      <td>2.917772</td>\n",
       "      <td>56.55</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.441306</td>\n",
       "      <td>0.794351</td>\n",
       "      <td>2.118270</td>\n",
       "      <td>2.736099</td>\n",
       "      <td>2.206531</td>\n",
       "      <td>56.65</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.351494</td>\n",
       "      <td>1.669596</td>\n",
       "      <td>2.284710</td>\n",
       "      <td>1.757469</td>\n",
       "      <td>1.493849</td>\n",
       "      <td>56.90</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.313485</td>\n",
       "      <td>1.926445</td>\n",
       "      <td>1.401051</td>\n",
       "      <td>1.138354</td>\n",
       "      <td>1.401051</td>\n",
       "      <td>57.10</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.605013</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>-0.172861</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>0.172861</td>\n",
       "      <td>57.85</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.515464</td>\n",
       "      <td>-0.773196</td>\n",
       "      <td>-0.515464</td>\n",
       "      <td>-0.429553</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>58.20</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.259067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086356</td>\n",
       "      <td>1.381693</td>\n",
       "      <td>0.863558</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.346320</td>\n",
       "      <td>1.645022</td>\n",
       "      <td>1.125541</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>57.75</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.086356</td>\n",
       "      <td>1.381693</td>\n",
       "      <td>0.863558</td>\n",
       "      <td>0.690846</td>\n",
       "      <td>0.690846</td>\n",
       "      <td>57.90</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.294219</td>\n",
       "      <td>0.776531</td>\n",
       "      <td>0.603969</td>\n",
       "      <td>0.603969</td>\n",
       "      <td>0.517688</td>\n",
       "      <td>57.95</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.511073</td>\n",
       "      <td>-0.681431</td>\n",
       "      <td>-0.681431</td>\n",
       "      <td>-0.766610</td>\n",
       "      <td>-2.896082</td>\n",
       "      <td>58.70</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.171233</td>\n",
       "      <td>-0.171233</td>\n",
       "      <td>-0.256849</td>\n",
       "      <td>-2.397260</td>\n",
       "      <td>-2.654110</td>\n",
       "      <td>58.40</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.085763</td>\n",
       "      <td>-2.229846</td>\n",
       "      <td>-2.487136</td>\n",
       "      <td>-1.629503</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.085763</td>\n",
       "      <td>-2.229846</td>\n",
       "      <td>-2.487136</td>\n",
       "      <td>-1.629503</td>\n",
       "      <td>-1.972556</td>\n",
       "      <td>58.30</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-2.145923</td>\n",
       "      <td>-2.403433</td>\n",
       "      <td>-1.545064</td>\n",
       "      <td>-1.888412</td>\n",
       "      <td>-1.030043</td>\n",
       "      <td>58.25</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "      <td>57.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.263158</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>1.140351</td>\n",
       "      <td>-0.087719</td>\n",
       "      <td>57.00</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "      <td>57.65</td>\n",
       "      <td>56.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.879507</td>\n",
       "      <td>0.527704</td>\n",
       "      <td>1.407212</td>\n",
       "      <td>0.175901</td>\n",
       "      <td>0.175901</td>\n",
       "      <td>56.85</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "      <td>57.65</td>\n",
       "      <td>56.95</td>\n",
       "      <td>56.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.348736</td>\n",
       "      <td>0.523104</td>\n",
       "      <td>-0.697472</td>\n",
       "      <td>-0.697472</td>\n",
       "      <td>-1.133391</td>\n",
       "      <td>57.35</td>\n",
       "      <td>57.15</td>\n",
       "      <td>57.65</td>\n",
       "      <td>56.95</td>\n",
       "      <td>56.95</td>\n",
       "      <td>56.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1.010101</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>-0.820707</td>\n",
       "      <td>-0.315657</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>79.20</td>\n",
       "      <td>80.00</td>\n",
       "      <td>79.40</td>\n",
       "      <td>78.55</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-1.812500</td>\n",
       "      <td>-1.312500</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.00</td>\n",
       "      <td>79.40</td>\n",
       "      <td>78.55</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>-1.070529</td>\n",
       "      <td>-0.566751</td>\n",
       "      <td>0.125945</td>\n",
       "      <td>0.755668</td>\n",
       "      <td>1.322418</td>\n",
       "      <td>79.40</td>\n",
       "      <td>78.55</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>0.509230</td>\n",
       "      <td>1.209421</td>\n",
       "      <td>1.845958</td>\n",
       "      <td>2.418842</td>\n",
       "      <td>2.673456</td>\n",
       "      <td>78.55</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>0.696643</td>\n",
       "      <td>1.329956</td>\n",
       "      <td>1.899937</td>\n",
       "      <td>2.153262</td>\n",
       "      <td>3.356555</td>\n",
       "      <td>78.95</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>0.628931</td>\n",
       "      <td>1.194969</td>\n",
       "      <td>1.446541</td>\n",
       "      <td>2.641509</td>\n",
       "      <td>3.773585</td>\n",
       "      <td>79.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>0.248602</td>\n",
       "      <td>1.429459</td>\n",
       "      <td>2.548167</td>\n",
       "      <td>1.491610</td>\n",
       "      <td>1.615911</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1.177929</td>\n",
       "      <td>2.293862</td>\n",
       "      <td>1.239926</td>\n",
       "      <td>1.363918</td>\n",
       "      <td>0.681959</td>\n",
       "      <td>80.65</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1.102941</td>\n",
       "      <td>0.061275</td>\n",
       "      <td>0.183824</td>\n",
       "      <td>-0.490196</td>\n",
       "      <td>-0.796569</td>\n",
       "      <td>81.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>-1.030303</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>-1.575758</td>\n",
       "      <td>-1.878788</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>82.50</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>0.122474</td>\n",
       "      <td>-0.551133</td>\n",
       "      <td>-0.857318</td>\n",
       "      <td>0.489896</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>81.65</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>-0.672783</td>\n",
       "      <td>-0.978593</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.489297</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>-0.307882</td>\n",
       "      <td>1.046798</td>\n",
       "      <td>0.677340</td>\n",
       "      <td>0.184729</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>81.20</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>1.358863</td>\n",
       "      <td>0.988264</td>\n",
       "      <td>0.494132</td>\n",
       "      <td>0.741198</td>\n",
       "      <td>1.111797</td>\n",
       "      <td>80.95</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>-0.365631</td>\n",
       "      <td>-0.853138</td>\n",
       "      <td>-0.609385</td>\n",
       "      <td>-0.243754</td>\n",
       "      <td>0.182815</td>\n",
       "      <td>82.05</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>-0.489297</td>\n",
       "      <td>-0.244648</td>\n",
       "      <td>0.122324</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.122324</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0.245851</td>\n",
       "      <td>0.614628</td>\n",
       "      <td>1.044868</td>\n",
       "      <td>0.614628</td>\n",
       "      <td>-1.167793</td>\n",
       "      <td>81.35</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>0.367872</td>\n",
       "      <td>0.797057</td>\n",
       "      <td>0.367872</td>\n",
       "      <td>-1.410178</td>\n",
       "      <td>-0.980993</td>\n",
       "      <td>81.55</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>0.427611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.771533</td>\n",
       "      <td>-1.343922</td>\n",
       "      <td>-0.610874</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>-0.425791</td>\n",
       "      <td>-2.189781</td>\n",
       "      <td>-1.763990</td>\n",
       "      <td>-1.034063</td>\n",
       "      <td>0.486618</td>\n",
       "      <td>82.20</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>-1.771533</td>\n",
       "      <td>-1.343922</td>\n",
       "      <td>-0.610874</td>\n",
       "      <td>0.916310</td>\n",
       "      <td>0.794136</td>\n",
       "      <td>81.85</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0.435323</td>\n",
       "      <td>1.181592</td>\n",
       "      <td>2.736318</td>\n",
       "      <td>2.611940</td>\n",
       "      <td>3.606965</td>\n",
       "      <td>80.40</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>0.743034</td>\n",
       "      <td>2.291022</td>\n",
       "      <td>2.167183</td>\n",
       "      <td>3.157895</td>\n",
       "      <td>3.343653</td>\n",
       "      <td>80.75</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>1.536570</td>\n",
       "      <td>1.413645</td>\n",
       "      <td>2.397050</td>\n",
       "      <td>2.581438</td>\n",
       "      <td>1.475108</td>\n",
       "      <td>81.35</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>-0.121065</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>1.029056</td>\n",
       "      <td>-0.060533</td>\n",
       "      <td>0.060533</td>\n",
       "      <td>82.60</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>0.180072</td>\n",
       "      <td>-0.900360</td>\n",
       "      <td>-0.780312</td>\n",
       "      <td>-0.960384</td>\n",
       "      <td>-0.360144</td>\n",
       "      <td>83.30</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>-1.078490</td>\n",
       "      <td>-0.958658</td>\n",
       "      <td>-1.138406</td>\n",
       "      <td>-0.539245</td>\n",
       "      <td>-2.037148</td>\n",
       "      <td>83.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.00</td>\n",
       "      <td>81.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.121139</td>\n",
       "      <td>-0.060569</td>\n",
       "      <td>0.545124</td>\n",
       "      <td>-0.969110</td>\n",
       "      <td>-0.726832</td>\n",
       "      <td>82.55</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.50</td>\n",
       "      <td>83.00</td>\n",
       "      <td>81.75</td>\n",
       "      <td>81.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1268 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            d1        d2        d3        d4        d5  close    cl1    cl2  \\\n",
       "0     0.185529  0.000000 -0.092764  2.875696  2.782931  53.90  54.00  53.90   \n",
       "1    -0.185185 -0.277778  2.685185  2.592593  2.037037  54.00  53.90  53.85   \n",
       "2    -0.092764  2.875696  2.782931  2.226345  3.061224  53.90  53.85  55.45   \n",
       "3     2.971216  2.878366  2.321263  3.156917  3.342618  53.85  55.45  55.40   \n",
       "4    -0.090171 -0.631199  0.180343  0.360685  0.721371  55.45  55.40  55.10   \n",
       "5    -0.541516  0.270758  0.451264  0.812274  0.722022  55.40  55.10  55.55   \n",
       "6     0.816697  0.998185  1.361162  1.270417  2.359347  55.10  55.55  55.65   \n",
       "7     0.180018  0.540054  0.450045  1.530153  1.800180  55.55  55.65  55.85   \n",
       "8     0.359389  0.269542  1.347709  1.617251  1.796945  55.65  55.85  55.80   \n",
       "9    -0.089526  0.984781  1.253357  1.432408  1.880036  55.85  55.80  56.40   \n",
       "10    1.075269  1.344086  1.523297  1.971326  2.329749  55.80  56.40  56.55   \n",
       "11    0.265957  0.443262  0.886525  1.241135  2.570922  56.40  56.55  56.65   \n",
       "12    0.176835  0.618921  0.972591  2.298851  2.917772  56.55  56.65  56.90   \n",
       "13    0.441306  0.794351  2.118270  2.736099  2.206531  56.65  56.90  57.10   \n",
       "14    0.351494  1.669596  2.284710  1.757469  1.493849  56.90  57.10  57.85   \n",
       "15    1.313485  1.926445  1.401051  1.138354  1.401051  57.10  57.85  58.20   \n",
       "16    0.605013  0.086430 -0.172861  0.086430  0.172861  57.85  58.20  57.90   \n",
       "17   -0.515464 -0.773196 -0.515464 -0.429553  0.859107  58.20  57.90  57.75   \n",
       "18   -0.259067  0.000000  0.086356  1.381693  0.863558  57.90  57.75  57.90   \n",
       "19    0.259740  0.346320  1.645022  1.125541  0.952381  57.75  57.90  57.95   \n",
       "20    0.086356  1.381693  0.863558  0.690846  0.690846  57.90  57.95  58.70   \n",
       "21    1.294219  0.776531  0.603969  0.603969  0.517688  57.95  58.70  58.40   \n",
       "22   -0.511073 -0.681431 -0.681431 -0.766610 -2.896082  58.70  58.40  58.30   \n",
       "23   -0.171233 -0.171233 -0.256849 -2.397260 -2.654110  58.40  58.30  58.30   \n",
       "24    0.000000 -0.085763 -2.229846 -2.487136 -1.629503  58.30  58.30  58.25   \n",
       "25   -0.085763 -2.229846 -2.487136 -1.629503 -1.972556  58.30  58.25  57.00   \n",
       "26   -2.145923 -2.403433 -1.545064 -1.888412 -1.030043  58.25  57.00  56.85   \n",
       "27   -0.263158  0.614035  0.263158  1.140351 -0.087719  57.00  56.85  57.35   \n",
       "28    0.879507  0.527704  1.407212  0.175901  0.175901  56.85  57.35  57.15   \n",
       "29   -0.348736  0.523104 -0.697472 -0.697472 -1.133391  57.35  57.15  57.65   \n",
       "...        ...       ...       ...       ...       ...    ...    ...    ...   \n",
       "1238  1.010101  0.252525 -0.820707 -0.315657  0.378788  79.20  80.00  79.40   \n",
       "1239 -0.750000 -1.812500 -1.312500 -0.625000  0.000000  80.00  79.40  78.55   \n",
       "1240 -1.070529 -0.566751  0.125945  0.755668  1.322418  79.40  78.55  78.95   \n",
       "1241  0.509230  1.209421  1.845958  2.418842  2.673456  78.55  78.95  79.50   \n",
       "1242  0.696643  1.329956  1.899937  2.153262  3.356555  78.95  79.50  80.00   \n",
       "1243  0.628931  1.194969  1.446541  2.641509  3.773585  79.50  80.00  80.45   \n",
       "1244  0.562500  0.812500  2.000000  3.125000  2.062500  80.00  80.45  80.65   \n",
       "1245  0.248602  1.429459  2.548167  1.491610  1.615911  80.45  80.65  81.60   \n",
       "1246  1.177929  2.293862  1.239926  1.363918  0.681959  80.65  81.60  82.50   \n",
       "1247  1.102941  0.061275  0.183824 -0.490196 -0.796569  81.60  82.50  81.65   \n",
       "1248 -1.030303 -0.909091 -1.575758 -1.878788 -0.545455  82.50  81.65  81.75   \n",
       "1249  0.122474 -0.551133 -0.857318  0.489896  0.122474  81.65  81.75  81.20   \n",
       "1250 -0.672783 -0.978593  0.366972  0.000000 -0.489297  81.75  81.20  80.95   \n",
       "1251 -0.307882  1.046798  0.677340  0.184729  0.431034  81.20  80.95  82.05   \n",
       "1252  1.358863  0.988264  0.494132  0.741198  1.111797  80.95  82.05  81.75   \n",
       "1253 -0.365631 -0.853138 -0.609385 -0.243754  0.182815  82.05  81.75  81.35   \n",
       "1254 -0.489297 -0.244648  0.122324  0.550459  0.122324  81.75  81.35  81.55   \n",
       "1255  0.245851  0.614628  1.044868  0.614628 -1.167793  81.35  81.55  81.85   \n",
       "1256  0.367872  0.797057  0.367872 -1.410178 -0.980993  81.55  81.85  82.20   \n",
       "1257  0.427611  0.000000 -1.771533 -1.343922 -0.610874  81.85  82.20  81.85   \n",
       "1258 -0.425791 -2.189781 -1.763990 -1.034063  0.486618  82.20  81.85  80.40   \n",
       "1259 -1.771533 -1.343922 -0.610874  0.916310  0.794136  81.85  80.40  80.75   \n",
       "1260  0.435323  1.181592  2.736318  2.611940  3.606965  80.40  80.75  81.35   \n",
       "1261  0.743034  2.291022  2.167183  3.157895  3.343653  80.75  81.35  82.60   \n",
       "1262  1.536570  1.413645  2.397050  2.581438  1.475108  81.35  82.60  82.50   \n",
       "1263 -0.121065  0.847458  1.029056 -0.060533  0.060533  82.60  82.50  83.30   \n",
       "1264  0.969697  1.151515  0.060606  0.181818  0.000000  82.50  83.30  83.45   \n",
       "1265  0.180072 -0.900360 -0.780312 -0.960384 -0.360144  83.30  83.45  82.55   \n",
       "1266 -1.078490 -0.958658 -1.138406 -0.539245 -2.037148  83.45  82.55  82.65   \n",
       "1267  0.121139 -0.060569  0.545124 -0.969110 -0.726832  82.55  82.65  82.50   \n",
       "\n",
       "        cl3    cl4    cl5  \n",
       "0     53.85  55.45  55.40  \n",
       "1     55.45  55.40  55.10  \n",
       "2     55.40  55.10  55.55  \n",
       "3     55.10  55.55  55.65  \n",
       "4     55.55  55.65  55.85  \n",
       "5     55.65  55.85  55.80  \n",
       "6     55.85  55.80  56.40  \n",
       "7     55.80  56.40  56.55  \n",
       "8     56.40  56.55  56.65  \n",
       "9     56.55  56.65  56.90  \n",
       "10    56.65  56.90  57.10  \n",
       "11    56.90  57.10  57.85  \n",
       "12    57.10  57.85  58.20  \n",
       "13    57.85  58.20  57.90  \n",
       "14    58.20  57.90  57.75  \n",
       "15    57.90  57.75  57.90  \n",
       "16    57.75  57.90  57.95  \n",
       "17    57.90  57.95  58.70  \n",
       "18    57.95  58.70  58.40  \n",
       "19    58.70  58.40  58.30  \n",
       "20    58.40  58.30  58.30  \n",
       "21    58.30  58.30  58.25  \n",
       "22    58.30  58.25  57.00  \n",
       "23    58.25  57.00  56.85  \n",
       "24    57.00  56.85  57.35  \n",
       "25    56.85  57.35  57.15  \n",
       "26    57.35  57.15  57.65  \n",
       "27    57.15  57.65  56.95  \n",
       "28    57.65  56.95  56.95  \n",
       "29    56.95  56.95  56.70  \n",
       "...     ...    ...    ...  \n",
       "1238  78.55  78.95  79.50  \n",
       "1239  78.95  79.50  80.00  \n",
       "1240  79.50  80.00  80.45  \n",
       "1241  80.00  80.45  80.65  \n",
       "1242  80.45  80.65  81.60  \n",
       "1243  80.65  81.60  82.50  \n",
       "1244  81.60  82.50  81.65  \n",
       "1245  82.50  81.65  81.75  \n",
       "1246  81.65  81.75  81.20  \n",
       "1247  81.75  81.20  80.95  \n",
       "1248  81.20  80.95  82.05  \n",
       "1249  80.95  82.05  81.75  \n",
       "1250  82.05  81.75  81.35  \n",
       "1251  81.75  81.35  81.55  \n",
       "1252  81.35  81.55  81.85  \n",
       "1253  81.55  81.85  82.20  \n",
       "1254  81.85  82.20  81.85  \n",
       "1255  82.20  81.85  80.40  \n",
       "1256  81.85  80.40  80.75  \n",
       "1257  80.40  80.75  81.35  \n",
       "1258  80.75  81.35  82.60  \n",
       "1259  81.35  82.60  82.50  \n",
       "1260  82.60  82.50  83.30  \n",
       "1261  82.50  83.30  83.45  \n",
       "1262  83.30  83.45  82.55  \n",
       "1263  83.45  82.55  82.65  \n",
       "1264  82.55  82.65  82.50  \n",
       "1265  82.65  82.50  83.00  \n",
       "1266  82.50  83.00  81.75  \n",
       "1267  83.00  81.75  81.95  \n",
       "\n",
       "[1268 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_box = []\n",
    "for f in frames:\n",
    "    X_box.append(f.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data_box, target_box, train_rate=.9, test_rate=.1):\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    if (train_rate + test_rate != 1):\n",
    "        test_rate = 1 - train_rate\n",
    "    \n",
    "    for i in range(len(data_box)):\n",
    "        tot = len(data_box[i]) # 總長度\n",
    "        tra = int(np.ceil(tot * train_rate) - 1)\n",
    "        x_train.append(list(data_box[i][:tra]))\n",
    "        x_test.append(list(data_box[i][tra:]))\n",
    "        \n",
    "        tmp_ytr = []\n",
    "        tmp_yte = []\n",
    "        for j in range(len(target_box[i])):\n",
    "            tmp_ytr.append(list(target_box[i][j][:tra]))\n",
    "            tmp_yte.append(list(target_box[i][j][tra:]))\n",
    "        y_train.append(tmp_ytr)\n",
    "        y_test.append(tmp_yte)\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(X_box, Y_box, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_50tr, y_50tr, x_50te, y_50te = train_test_split(X_box, Y_box, 0.5)\n",
    "x_ftr, y_ftr, x_fte, y_fte = train_test_split(x_50te, y_50te, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (128, 114)\n",
      "1 (128, 114)\n",
      "2 (128, 114)\n",
      "3 (128, 114)\n",
      "4 (128, 114)\n",
      "5 (128, 114)\n",
      "6 (128, 114)\n",
      "7 (128, 114)\n",
      "8 (128, 114)\n",
      "9 (128, 114)\n",
      "10 (128, 114)\n",
      "11 (127, 114)\n",
      "12 (127, 114)\n",
      "13 (128, 114)\n",
      "14 (24, 114)\n",
      "15 (21, 114)\n",
      "16 (14, 114)\n",
      "17 (11, 114)\n"
     ]
    }
   ],
   "source": [
    "for i_fte, fte in enumerate(x_fte):\n",
    "    print(i_fte, np.array(fte).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.51612903225806495,\n",
       "  -0.12836970474967632,\n",
       "  -1.1889460154241676,\n",
       "  0.19512195121950804,\n",
       "  0.48685491723467111,\n",
       "  0.77519379844960734,\n",
       "  0.48076923076923772,\n",
       "  0.31897926634768059,\n",
       "  -0.19077901430842198,\n",
       "  -0.28671551449506172],\n",
       " [0.51612903225806495,\n",
       "  0.3870967741935516,\n",
       "  -1.3157894736842108,\n",
       "  -0.99614395886890184,\n",
       "  0.68292682926829551,\n",
       "  1.2658227848101284,\n",
       "  1.2596899224806222,\n",
       "  0.80128205128205143,\n",
       "  0.12759170653907226,\n",
       "  -0.47694753577106058,\n",
       "  -0.19114367633004864],\n",
       " [0.3870967741935516,\n",
       "  -0.80645161290322576,\n",
       "  -1.1232349165596964,\n",
       "  -0.51413881748072032,\n",
       "  1.4634146341463392,\n",
       "  1.7526777020447994,\n",
       "  1.5826873385012867,\n",
       "  0.60897435897436292,\n",
       "  -0.15948963317384596,\n",
       "  -0.38155802861685528,\n",
       "  -0.4460019114367651],\n",
       " [-0.80645161290322576,\n",
       "  -0.61290322580645573,\n",
       "  -0.64184852374839307,\n",
       "  0.25706940874035439,\n",
       "  1.9512195121951263,\n",
       "  2.0772476468679022,\n",
       "  1.388888888888888,\n",
       "  0.32051282051282504,\n",
       "  -0.063795853269547453,\n",
       "  -0.63593004769475137,\n",
       "  -0.38228735266008601],\n",
       " [-0.61290322580645573,\n",
       "  -0.12903225806451338,\n",
       "  0.12836970474967632,\n",
       "  0.73907455012853607,\n",
       "  2.27642276422764,\n",
       "  1.8825056799740405,\n",
       "  1.0981912144702839,\n",
       "  0.41666666666666347,\n",
       "  -0.31897926634769191,\n",
       "  -0.57233704292527732,\n",
       "  -1.242433896145271],\n",
       " [31.0,\n",
       "  31.0,\n",
       "  31.16,\n",
       "  31.120000000000001,\n",
       "  30.75,\n",
       "  30.809999999999999,\n",
       "  30.960000000000001,\n",
       "  31.199999999999999,\n",
       "  31.350000000000001,\n",
       "  31.449999999999999,\n",
       "  31.390000000000001],\n",
       " [31.0,\n",
       "  31.16,\n",
       "  31.120000000000001,\n",
       "  30.75,\n",
       "  30.809999999999999,\n",
       "  30.960000000000001,\n",
       "  31.199999999999999,\n",
       "  31.350000000000001,\n",
       "  31.449999999999999,\n",
       "  31.390000000000001,\n",
       "  31.300000000000001],\n",
       " [31.16,\n",
       "  31.120000000000001,\n",
       "  30.75,\n",
       "  30.809999999999999,\n",
       "  30.960000000000001,\n",
       "  31.199999999999999,\n",
       "  31.350000000000001,\n",
       "  31.449999999999999,\n",
       "  31.390000000000001,\n",
       "  31.300000000000001,\n",
       "  31.329999999999998],\n",
       " [31.120000000000001,\n",
       "  30.75,\n",
       "  30.809999999999999,\n",
       "  30.960000000000001,\n",
       "  31.199999999999999,\n",
       "  31.350000000000001,\n",
       "  31.449999999999999,\n",
       "  31.390000000000001,\n",
       "  31.300000000000001,\n",
       "  31.329999999999998,\n",
       "  31.25],\n",
       " [30.75,\n",
       "  30.809999999999999,\n",
       "  30.960000000000001,\n",
       "  31.199999999999999,\n",
       "  31.350000000000001,\n",
       "  31.449999999999999,\n",
       "  31.390000000000001,\n",
       "  31.300000000000001,\n",
       "  31.329999999999998,\n",
       "  31.25,\n",
       "  31.27],\n",
       " [30.809999999999999,\n",
       "  30.960000000000001,\n",
       "  31.199999999999999,\n",
       "  31.350000000000001,\n",
       "  31.449999999999999,\n",
       "  31.390000000000001,\n",
       "  31.300000000000001,\n",
       "  31.329999999999998,\n",
       "  31.25,\n",
       "  31.27,\n",
       "  31.0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fte[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-1][-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as var\n",
    "from torch import nn, cuda\n",
    "from torch.utils.data import Dataset, DataLoader, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSet(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(DSet, self).__init__()\n",
    "        self.base_x = x\n",
    "        self.base_y = y\n",
    "    def __getitem__(self, index):\n",
    "        while index < 0:\n",
    "            index += self.__len__()\n",
    "        while index >= self.__len__():\n",
    "            index -= self.__len__()\n",
    "\n",
    "        for i in range(len(self.base_x)):\n",
    "            if index > len(self.base_x[i]) - 1 - 8:\n",
    "                index -= (len(self.base_x[i]) - 1 - 8)\n",
    "            else:\n",
    "                # y will output ['d1', 'd2', 'd3', 'd4', 'd5', 'close', 'cl1', 'cl2', 'cl3', 'cl4', 'cl5']\n",
    "                y = np.array([self.base_y[i][x][index + 8] for x in range(len(self.base_y[i]))])\n",
    "                return {\"X\":(torch.FloatTensor([self.base_x[i][index : index + 9]])), \"Y\":y, \"close\":(torch.FloatTensor([self.base_y[i][5][index + 8]]))}\n",
    "\n",
    "    def __len__(self):\n",
    "        tot = 0\n",
    "        for x in self.base_x:\n",
    "            if (len(x) - 9) >= 0:\n",
    "                tot += (len(x) - 9)\n",
    "            else:\n",
    "                tot += 0\n",
    "        return tot + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSet2(Dataset): # for fine tune\n",
    "    def __init__(self, x, y):\n",
    "        super(DSet2, self).__init__()\n",
    "        self.base_x = x\n",
    "        self.base_y = y\n",
    "    def __getitem__(self, index):\n",
    "        while index < 0:\n",
    "            index += self.__len__()\n",
    "        while index >= self.__len__():\n",
    "            index -= self.__len__()\n",
    "\n",
    "\n",
    "        # y will output ['d1', 'd2', 'd3', 'd4', 'd5', 'close', 'cl1', 'cl2', 'cl3', 'cl4', 'cl5']\n",
    "        y = np.array([self.base_y[x][index + 8] for x in range(len(self.base_y))])\n",
    "        return {\"X\":(torch.FloatTensor([self.base_x[index : index + 9]])), \"Y\":y, \"close\":(torch.FloatTensor([self.base_y[5][index + 8]]))}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        tot = 0\n",
    "        tot += (len(self.base_x) - 9)\n",
    "        if tot < 0:\n",
    "            tot = 0\n",
    "        return tot + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DSet(x_train, y_train)\n",
    "valid = DSet(x_test, y_test)\n",
    "\n",
    "finetune_tr = []\n",
    "for i in range(len(x_ftr)):\n",
    "    finetune_tr.append(DSet2(x_ftr[i], y_ftr[i]))\n",
    "\n",
    "finetune_te = []\n",
    "for i in range(len(x_fte)):\n",
    "    finetune_te.append(DSet2(x_fte[i], y_fte[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': \n",
       " ( 0 ,.,.) = \n",
       "   -0.0078  -0.0078  -0.0029  ...    0.0000   0.0000   0.0000\n",
       "   -0.0058  -0.0058  -0.0021  ...    0.0000   0.0000   0.0000\n",
       "   -0.0070  -0.0069  -0.0041  ...    0.0000   0.0000   0.0000\n",
       "             ...               ⋱              ...            \n",
       "    0.0148   0.0153   0.0118  ...    0.0000   0.0000   0.0000\n",
       "    0.0129   0.0135   0.0081  ...    0.0000   0.0000   0.0000\n",
       "    0.0150   0.0154   0.0077  ...    0.0000   0.0000   0.0000\n",
       " [torch.FloatTensor of size 1x9x114],\n",
       " 'Y': array([ -0.08952551,   0.98478066,   1.25335721,   1.43240824,\n",
       "          1.88003581,  55.85      ,  55.8       ,  56.4       ,\n",
       "         56.55      ,  56.65      ,  56.9       ]),\n",
       " 'close': \n",
       "  55.8500\n",
       " [torch.FloatTensor of size 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'X': \n",
       " ( 0 ,.,.) = \n",
       "     0.0099    0.0100    0.0019  ...     0.0000    0.0000    0.0000\n",
       "     0.0077    0.0079    0.0002  ...     0.0000    0.0000    0.0000\n",
       "     0.0051    0.0052   -0.0016  ...     0.0000    0.0000    0.0000\n",
       "               ...                ⋱                ...             \n",
       "     0.0075    0.0075    0.0034  ...     0.0000    0.0000    0.0000\n",
       "     0.0078    0.0078    0.0039  ...     0.0000    0.0000    0.0000\n",
       "     0.0068    0.0067    0.0029  ...     0.0000    0.0000    0.0000\n",
       " [torch.FloatTensor of size 1x9x114],\n",
       " 'Y': array([ -0.0452284 ,  -0.09045681,  -0.09045681,   0.13568521,\n",
       "          0.0452284 ,  22.11      ,  22.1       ,  22.09      ,\n",
       "         22.09      ,  22.14      ,  22.12      ]),\n",
       " 'close': \n",
       "  22.1100\n",
       " [torch.FloatTensor of size 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train))\n",
    "train[16084]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax = lambda x : np.round(np.log(np.exp(x) / np.sum(np.exp(x))), 4)\n",
    "def Build_Y(cp_1D, classes = [x for x in np.arange(-9.5, 10, 1)]):\n",
    "    out = []\n",
    "    for x in cp_1D:\n",
    "        tmp = []\n",
    "        for c in classes:\n",
    "            tmp.append(-(abs(x - c)))\n",
    "        out.append(log_softmax(tmp))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleCRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleCRNN, self).__init__()\n",
    "        # torch.Size([9, 1, 40])\n",
    "        # torch.Size([1, 1, 360])\n",
    "        self.lstm0 = nn.LSTM(\n",
    "            input_size = 114,\n",
    "            hidden_size = 20,\n",
    "            num_layers = 1,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        self.h0 = None\n",
    "        \n",
    "        # torch.Size([7, 1, 40])\n",
    "        # torch.Size([1, 1, 280])\n",
    "        self.conv1 = nn.Conv2d(1, 1, 3)\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size = 112,\n",
    "            hidden_size = 20,\n",
    "            num_layers = 1,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        self.h1 = None\n",
    "        \n",
    "        # torch.Size([4, 1, 40])\n",
    "        # torch.Size([1, 1, 160])\n",
    "        self.conv2 = nn.Conv2d(1, 1, 6)\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size = 109,\n",
    "            hidden_size = 20,\n",
    "            num_layers = 1,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        self.h2 = None\n",
    "        \n",
    "        # torch.Size([1, 1, 40])\n",
    "        self.conv3 = nn.Conv2d(1, 1, 9)\n",
    "        self.lstm3 = nn.LSTM(\n",
    "            input_size = 106,\n",
    "            hidden_size = 20,\n",
    "            num_layers = 1,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        self.h3 = None\n",
    "        \n",
    "        self.resizer = [nn.Linear(840, 1)for i in range(5)]\n",
    "        for m in range(len(self.resizer)):\n",
    "            self.add_module('resizer-'+str(m + 1), self.resizer[m])\n",
    "    def forward(self, x, val):\n",
    "        out0, self.h0 = self.lstm0(x.view(9, 1, -1), self.h0)\n",
    "        out = out0.view(1, -1)\n",
    "        \n",
    "        c = self.conv1(x.view(1, 1, 9, -1)).view(7, 1, -1)\n",
    "        out1, self.h1 = self.lstm1(c, self.h1)\n",
    "        out = torch.cat((out, out1.view(1, -1)), 1)\n",
    "        \n",
    "        c = self.conv2(x.view(1, 1, 9, -1)).view(4, 1, -1)\n",
    "        out2, self.h2 = self.lstm2(c, self.h2)\n",
    "        out = torch.cat((out, out2.view(1, -1)), 1)\n",
    "        \n",
    "        c = self.conv3(x.view(1, 1, 9, -1)).view(1, 1, -1)\n",
    "        out3, self.h3 = self.lstm3(c, self.h3)\n",
    "        out = torch.cat((out, out3.view(1, -1)), 1)\n",
    "        \n",
    "        updn = []\n",
    "        for i_r, r in enumerate(self.resizer):\n",
    "            updn.append(r(out.view(1, -1)))\n",
    "        \n",
    "        ans = []\n",
    "        for i_ud, ud in enumerate(updn):\n",
    "            ans.append(torch.mul(val.view(1, -1), ud))\n",
    "        \n",
    "        updn[0] = torch.sign(ans[0] - val)\n",
    "        for i in range(1, len(ans)):\n",
    "            updn[i] = torch.sign(ans[i] - ans[i - 1])\n",
    "        \n",
    "        return updn, ans\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last State has load!\n"
     ]
    }
   ],
   "source": [
    "net = nn.DataParallel(simpleCRNN().cuda())\n",
    "try:\n",
    "    net.load_state_dict(torch.load(\"./cr2.pth\"))\n",
    "except:\n",
    "    try:\n",
    "        net.load_state_dict(torch.load(\"./cr2_base.pth\"))\n",
    "    except:\n",
    "        print(\"NO pre-trained model.\")\n",
    "    else:\n",
    "        print(\"Last State has load!\")\n",
    "else:\n",
    "    print(\"Last State has load!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): simpleCRNN(\n",
       "    (lstm0): LSTM(114, 20, bidirectional=True)\n",
       "    (conv1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (lstm1): LSTM(112, 20, bidirectional=True)\n",
       "    (conv2): Conv2d(1, 1, kernel_size=(6, 6), stride=(1, 1))\n",
       "    (lstm2): LSTM(109, 20, bidirectional=True)\n",
       "    (conv3): Conv2d(1, 1, kernel_size=(9, 9), stride=(1, 1))\n",
       "    (lstm3): LSTM(106, 20, bidirectional=True)\n",
       "    (resizer-1): Linear(in_features=840, out_features=1, bias=True)\n",
       "    (resizer-2): Linear(in_features=840, out_features=1, bias=True)\n",
       "    (resizer-3): Linear(in_features=840, out_features=1, bias=True)\n",
       "    (resizer-4): Linear(in_features=840, out_features=1, bias=True)\n",
       "    (resizer-5): Linear(in_features=840, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_Rate = 1e-3\n",
    "EPOCH = 0\n",
    "BATACH_SIZE = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = DataLoader(dataset=train, batch_size=BATACH_SIZE, num_workers=6, sampler=sampler.SequentialSampler(train), pin_memory=True)\n",
    "#train_dl = DataLoader(dataset=train, batch_size=BATACH_SIZE, num_workers=6, pin_memory=True, shuffle=True)\n",
    "valid_dl = DataLoader(dataset=valid, batch_size=5, num_workers=6, sampler=sampler.SequentialSampler(valid), pin_memory=True)\n",
    "\n",
    "finetune_tr_dl = []\n",
    "finetune_te_dl = []\n",
    "for i_ftr, ftr in enumerate(finetune_tr):\n",
    "    finetune_tr_dl.append(DataLoader(dataset=ftr, batch_size=20, num_workers=6, sampler=sampler.SequentialSampler(ftr), pin_memory=True))\n",
    "for i_fte, fte in enumerate(finetune_te):\n",
    "    finetune_te_dl.append(DataLoader(dataset=fte, batch_size=5, num_workers=6, sampler=sampler.SequentialSampler(fte), pin_memory=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = torch.optim.Adam(net.parameters(), lr=Learning_Rate)\n",
    "lf1 = nn.KLDivLoss()\n",
    "lf2 = nn.MSELoss()\n",
    "lf3 = nn.SmoothL1Loss()\n",
    "lf4 = lambda a, b : 1 if torch.equal(a.view(1, -1), b.view(1, -1)) else 0\n",
    "w = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "_100 = var(torch.FloatTensor([100])).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epo_score = []\n",
    "max_va = -1\n",
    "no_up = 0\n",
    "for epo in range(EPOCH):\n",
    "    print(\"Epoch Now:\",epo+1,\",Total:\",EPOCH)\n",
    "    scores = []\n",
    "    for i_batch, sample_batched in enumerate(train_dl):\n",
    "        for mini_batch in range(sample_batched['X'].size()[0]):\n",
    "            x = var(sample_batched['X'][mini_batch]).cuda()\n",
    "            val = var(sample_batched['close'][mini_batch]).cuda()\n",
    "            updn, ans = net(x, val)\n",
    "            op.zero_grad()\n",
    "            \n",
    "            y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][0 + 6]]])).cuda()\n",
    "            y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + 0] - sample_batched['Y'][mini_batch][5 + 0 + 0]])))).view(1,1,-1).cuda()\n",
    "            score = w[0] * (50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3))\n",
    "            loss = lf3((50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3)).view(1, -1), _100.view(1, -1))\n",
    "            for i_sm in range(1, 5):\n",
    "                y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][i_sm + 6]]])).cuda()\n",
    "                y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + i_sm] - sample_batched['Y'][mini_batch][5 + 0 + i_sm]])))).view(1,1,-1).cuda()\n",
    "                score += w[i_sm] * (50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3))\n",
    "                loss += lf3((50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3)).view(1, -1), _100.view(1, -1))\n",
    "            \n",
    "            loss.backward()\n",
    "            op.step()\n",
    "            scores.append(score.cpu().data.numpy()[0])\n",
    "            cuda.empty_cache()\n",
    "            \n",
    "        if (i_batch + 1) % 500 == 0:\n",
    "            print(\"500 Batches Trained!, Avg score = {0}\".format(np.average(scores[-100:])))\n",
    "            #torch.save(net.state_dict(), \"./cr2_base_E{0}_B{1}.pth\".format(epo, i_batch + 1))\n",
    "    \n",
    "    cuda.empty_cache()\n",
    "    print(\"Train score\", np.average(scores))\n",
    "    scores = []\n",
    "    for i_batch, sample_batched in enumerate(valid_dl):\n",
    "        for mini_batch in range(sample_batched['X'].size()[0]):\n",
    "            x = var(sample_batched['X'][mini_batch]).cuda()\n",
    "            val = var(sample_batched['close'][mini_batch]).cuda()\n",
    "            updn, ans = net(x, val)\n",
    "            op.zero_grad()\n",
    "            \n",
    "            y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][0 + 6]]])).cuda()\n",
    "            y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + 0] - sample_batched['Y'][mini_batch][5 + 0 + 0]])))).view(1,1,-1).cuda()\n",
    "            score = w[0] * (50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3))\n",
    "            for i_sm in range(1, 5):\n",
    "                y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][i_sm + 6]]])).cuda()\n",
    "                y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + i_sm] - sample_batched['Y'][mini_batch][5 + 0 + i_sm]])))).view(1,1,-1).cuda()\n",
    "                score += w[i_sm] * (50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3))\n",
    "            scores.append(score.cpu().data.numpy()[0])\n",
    "            cuda.empty_cache()\n",
    "    epo_score.append(np.average(scores))\n",
    "    print(\"Valid score\", epo_score[-1])\n",
    "    \n",
    "    if epo_score[-1] > max_va:\n",
    "        no_up = 0\n",
    "        max_va = epo_score[-1]\n",
    "    else:\n",
    "        no_up += 1\n",
    "    \n",
    "    torch.save(net.state_dict(), \"./cr2.pth\")\n",
    "    if no_up >= 10:\n",
    "        print(\"\\n End at the {0} epoch\".format(epo+1))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File# 1 Finetuning\n",
      "Load ./cr2_final_20180608_50.pth\n",
      "epoch# 1\n",
      "score 72.6211\n",
      "Valid: 74.8559\n",
      "epoch# 2\n",
      "score 72.401\n",
      "Valid: 74.5486\n",
      "epoch# 3\n",
      "score 72.4317\n",
      "Valid: 74.5612\n",
      "epoch# 4\n",
      "score 73.4865\n",
      "Valid: 74.8003\n",
      "epoch# 5\n",
      "score 72.382\n",
      "Valid: 73.0201\n",
      "epoch# 6\n",
      "score 72.4474\n",
      "Valid: 74.9401\n",
      "epoch# 7\n",
      "score 72.6669\n",
      "Valid: 72.8646\n",
      "epoch# 8\n",
      "score 72.4299\n",
      "Valid: 74.8739\n",
      "epoch# 9\n",
      "score 72.31\n",
      "Valid: 74.0224\n",
      "epoch# 10\n",
      "score 72.0057\n",
      "Valid: 72.713\n",
      "epoch# 11\n",
      "score 72.4963\n",
      "Valid: 72.5721\n",
      "epoch# 12\n",
      "score 72.2652\n",
      "Valid: 75.1946\n",
      "epoch# 13\n",
      "score 73.2009\n",
      "Valid: 71.8463\n",
      "epoch# 14\n",
      "score 72.9564\n",
      "Valid: 75.4222\n",
      "epoch# 15\n",
      "score 72.5324\n",
      "Valid: 72.9116\n",
      "epoch# 16\n",
      "score 72.7152\n",
      "Valid: 73.4104\n",
      "epoch# 17\n",
      "score 73.0003\n",
      "Valid: 72.9849\n",
      "epoch# 18\n",
      "score 72.5044\n",
      "Valid: 71.4151\n",
      "epoch# 19\n",
      "score 72.5838\n",
      "Valid: 75.2816\n",
      "epoch# 20\n",
      "score 72.6284\n",
      "Valid: 73.4725\n",
      "epoch# 21\n",
      "score 72.6626\n",
      "Valid: 72.8265\n",
      "epoch# 22\n",
      "score 72.9323\n",
      "Valid: 73.3595\n",
      "epoch# 23\n",
      "score 72.6461\n",
      "Valid: 74.8018\n",
      "epoch# 24\n",
      "score 72.722\n",
      "Valid: 71.6936\n",
      "Fintune has done! Average Score is 0.7262618255615234 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 73.91004943847656 / 1\n",
      "Batch#1, Score = 67.87285614013672 / 1\n",
      "Batch#2, Score = 61.04846954345703 / 1\n",
      "Batch#3, Score = 67.73118591308594 / 1\n",
      "Batch#4, Score = 61.578636169433594 / 1\n",
      "Batch#5, Score = 61.90824508666992 / 1\n",
      "Batch#6, Score = 75.40032196044922 / 1\n",
      "Batch#7, Score = 81.8790283203125 / 1\n",
      "Batch#8, Score = 66.47440338134766 / 1\n",
      "Batch#9, Score = 81.1881332397461 / 1\n",
      "Batch#10, Score = 68.56243133544922 / 1\n",
      "Batch#11, Score = 81.62249755859375 / 1\n",
      "Batch#12, Score = 74.40896606445312 / 1\n",
      "Batch#13, Score = 76.46744537353516 / 1\n",
      "Batch#14, Score = 71.89723205566406 / 1\n",
      "Batch#15, Score = 68.34950256347656 / 1\n",
      "Batch#16, Score = 85.44795227050781 / 1\n",
      "Batch#17, Score = 74.93257904052734 / 1\n",
      "Batch#18, Score = 61.6347541809082 / 1\n",
      "Batch#19, Score = 72.09178161621094 / 1\n",
      "Batch#20, Score = 71.8631820678711 / 1\n",
      "Batch#21, Score = 70.90436553955078 / 1\n",
      "Batch#22, Score = 70.02808380126953 / 1\n",
      "Batch#23, Score = 73.44409942626953 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 74.8719\n",
      "epoch# 2\n",
      "score 74.5844\n",
      "epoch# 3\n",
      "score 74.7212\n",
      "epoch# 4\n",
      "score 73.4473\n",
      "Fintune has done! Average Score is 0.7440619659423828 / 1\n",
      "Prepare to predict\n",
      "Result: [50, 1.0, 82.399773, 1.0, 82.496964, -1.0, 81.43206, -1.0, 80.654427, -1.0, 80.335747]\n",
      "\n",
      "File# 2 Finetuning\n",
      "Load ./cr2_final_20180608_51.pth\n",
      "epoch# 1\n",
      "score 72.0017\n",
      "Valid: 72.6548\n",
      "epoch# 2\n",
      "score 72.212\n",
      "Valid: 72.8181\n",
      "epoch# 3\n",
      "score 72.8483\n",
      "Valid: 70.9749\n",
      "epoch# 4\n",
      "score 73.7946\n",
      "Valid: 72.3822\n",
      "epoch# 5\n",
      "score 72.5207\n",
      "Valid: 70.2832\n",
      "epoch# 6\n",
      "score 73.6617\n",
      "Valid: 70.921\n",
      "epoch# 7\n",
      "score 73.0645\n",
      "Valid: 71.2195\n",
      "epoch# 8\n",
      "score 73.2664\n",
      "Valid: 71.1008\n",
      "epoch# 9\n",
      "score 72.5078\n",
      "Valid: 71.1755\n",
      "epoch# 10\n",
      "score 73.2308\n",
      "Valid: 70.9787\n",
      "epoch# 11\n",
      "score 73.3373\n",
      "Valid: 71.0823\n",
      "epoch# 12\n",
      "score 72.5252\n",
      "Valid: 71.0533\n",
      "Fintune has done! Average Score is 0.7291425323486328 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 77.03789520263672 / 1\n",
      "Batch#1, Score = 72.76972961425781 / 1\n",
      "Batch#2, Score = 63.41474151611328 / 1\n",
      "Batch#3, Score = 71.95916748046875 / 1\n",
      "Batch#4, Score = 68.0592269897461 / 1\n",
      "Batch#5, Score = 68.33467864990234 / 1\n",
      "Batch#6, Score = 77.85940551757812 / 1\n",
      "Batch#7, Score = 75.2020034790039 / 1\n",
      "Batch#8, Score = 76.92877960205078 / 1\n",
      "Batch#9, Score = 69.5467529296875 / 1\n",
      "Batch#10, Score = 71.58613586425781 / 1\n",
      "Batch#11, Score = 64.4840316772461 / 1\n",
      "Batch#12, Score = 71.80484771728516 / 1\n",
      "Batch#13, Score = 65.05320739746094 / 1\n",
      "Batch#14, Score = 70.62216186523438 / 1\n",
      "Batch#15, Score = 65.19320678710938 / 1\n",
      "Batch#16, Score = 75.9925765991211 / 1\n",
      "Batch#17, Score = 80.19544982910156 / 1\n",
      "Batch#18, Score = 78.39273071289062 / 1\n",
      "Batch#19, Score = 64.34087371826172 / 1\n",
      "Batch#20, Score = 75.28968811035156 / 1\n",
      "Batch#21, Score = 67.47627258300781 / 1\n",
      "Batch#22, Score = 62.506805419921875 / 1\n",
      "Batch#23, Score = 71.22835540771484 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 72.4814\n",
      "epoch# 2\n",
      "score 72.2281\n",
      "epoch# 3\n",
      "score 72.5485\n",
      "epoch# 4\n",
      "score 72.8046\n",
      "epoch# 5\n",
      "score 71.9382\n",
      "epoch# 6\n",
      "score 73.2412\n",
      "epoch# 7\n",
      "score 72.0502\n",
      "epoch# 8\n",
      "score 74.0345\n",
      "epoch# 9\n",
      "score 72.3556\n",
      "epoch# 10\n",
      "score 72.7955\n",
      "epoch# 11\n",
      "score 73.06\n",
      "Fintune has done! Average Score is 0.7268524169921875 / 1\n",
      "Prepare to predict\n",
      "Result: [51, 1.0, 34.537354, -1.0, 33.832523, 1.0, 34.173424, 1.0, 34.237579, -1.0, 33.140282]\n",
      "\n",
      "File# 3 Finetuning\n",
      "Load ./cr2_final_20180608_52.pth\n",
      "epoch# 1\n",
      "score 70.8828\n",
      "Valid: 72.6695\n",
      "epoch# 2\n",
      "score 71.0327\n",
      "Valid: 72.5654\n",
      "epoch# 3\n",
      "score 69.3373\n",
      "Valid: 72.4098\n",
      "epoch# 4\n",
      "score 69.9485\n",
      "Valid: 72.2933\n",
      "epoch# 5\n",
      "score 70.6196\n",
      "Valid: 72.4705\n",
      "epoch# 6\n",
      "score 70.8991\n",
      "Valid: 72.414\n",
      "epoch# 7\n",
      "score 70.5074\n",
      "Valid: 72.5146\n",
      "epoch# 8\n",
      "score 70.8173\n",
      "Valid: 72.5093\n",
      "epoch# 9\n",
      "score 69.8226\n",
      "Valid: 72.6609\n",
      "epoch# 10\n",
      "score 70.559\n",
      "Valid: 72.3263\n",
      "epoch# 11\n",
      "score 70.8074\n",
      "Valid: 71.861\n",
      "Fintune has done! Average Score is 0.7047579193115234 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 61.364166259765625 / 1\n",
      "Batch#1, Score = 65.93550109863281 / 1\n",
      "Batch#2, Score = 91.85465240478516 / 1\n",
      "Batch#3, Score = 73.42525482177734 / 1\n",
      "Batch#4, Score = 83.43624877929688 / 1\n",
      "Batch#5, Score = 83.2216796875 / 1\n",
      "Batch#6, Score = 71.32493591308594 / 1\n",
      "Batch#7, Score = 61.52388381958008 / 1\n",
      "Batch#8, Score = 77.33953094482422 / 1\n",
      "Batch#9, Score = 68.57337951660156 / 1\n",
      "Batch#10, Score = 77.49453735351562 / 1\n",
      "Batch#11, Score = 68.3369140625 / 1\n",
      "Batch#12, Score = 71.99504089355469 / 1\n",
      "Batch#13, Score = 71.6287612915039 / 1\n",
      "Batch#14, Score = 83.97482299804688 / 1\n",
      "Batch#15, Score = 68.7064208984375 / 1\n",
      "Batch#16, Score = 56.493690490722656 / 1\n",
      "Batch#17, Score = 63.06486892700195 / 1\n",
      "Batch#18, Score = 72.79646301269531 / 1\n",
      "Batch#19, Score = 63.33660888671875 / 1\n",
      "Batch#20, Score = 69.9162368774414 / 1\n",
      "Batch#21, Score = 63.990257263183594 / 1\n",
      "Batch#22, Score = 82.71954345703125 / 1\n",
      "Batch#23, Score = 72.2096939086914 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 71.8011\n",
      "epoch# 2\n",
      "score 73.7004\n",
      "epoch# 3\n",
      "score 72.9186\n",
      "epoch# 4\n",
      "score 71.4658\n",
      "epoch# 5\n",
      "score 72.4029\n",
      "Fintune has done! Average Score is 0.7245775604248047 / 1\n",
      "Prepare to predict\n",
      "Result: [52, 1.0, 51.602345, 1.0, 51.675709, -1.0, 51.541103, -1.0, 51.167606, 1.0, 52.347054]\n",
      "\n",
      "File# 4 Finetuning\n",
      "Load ./cr2_final_20180608_53.pth\n",
      "epoch# 1\n",
      "score 73.2358\n",
      "Valid: 69.8951\n",
      "epoch# 2\n",
      "score 73.5162\n",
      "Valid: 71.9591\n",
      "epoch# 3\n",
      "score 73.9226\n",
      "Valid: 72.3935\n",
      "epoch# 4\n",
      "score 73.1228\n",
      "Valid: 72.9008\n",
      "epoch# 5\n",
      "score 72.639\n",
      "Valid: 68.9634\n",
      "epoch# 6\n",
      "score 73.6143\n",
      "Valid: 68.9566\n",
      "epoch# 7\n",
      "score 72.9991\n",
      "Valid: 70.6017\n",
      "epoch# 8\n",
      "score 73.3107\n",
      "Valid: 72.1236\n",
      "epoch# 9\n",
      "score 74.4002\n",
      "Valid: 68.919\n",
      "epoch# 10\n",
      "score 73.4959\n",
      "Valid: 72.4422\n",
      "epoch# 11\n",
      "score 73.2219\n",
      "Valid: 70.3853\n",
      "epoch# 12\n",
      "score 73.8083\n",
      "Valid: 72.256\n",
      "epoch# 13\n",
      "score 72.9864\n",
      "Valid: 70.1981\n",
      "epoch# 14\n",
      "score 73.5972\n",
      "Valid: 71.7779\n",
      "Fintune has done! Average Score is 0.734193115234375 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 69.9858627319336 / 1\n",
      "Batch#1, Score = 71.50039672851562 / 1\n",
      "Batch#2, Score = 67.73037719726562 / 1\n",
      "Batch#3, Score = 70.23857116699219 / 1\n",
      "Batch#4, Score = 68.44389343261719 / 1\n",
      "Batch#5, Score = 72.83718872070312 / 1\n",
      "Batch#6, Score = 67.88023376464844 / 1\n",
      "Batch#7, Score = 74.1730728149414 / 1\n",
      "Batch#8, Score = 71.96954345703125 / 1\n",
      "Batch#9, Score = 71.00778198242188 / 1\n",
      "Batch#10, Score = 68.3104476928711 / 1\n",
      "Batch#11, Score = 73.46687316894531 / 1\n",
      "Batch#12, Score = 74.10338592529297 / 1\n",
      "Batch#13, Score = 72.95594024658203 / 1\n",
      "Batch#14, Score = 76.10803985595703 / 1\n",
      "Batch#15, Score = 71.39261627197266 / 1\n",
      "Batch#16, Score = 79.94111633300781 / 1\n",
      "Batch#17, Score = 70.10737609863281 / 1\n",
      "Batch#18, Score = 66.91612243652344 / 1\n",
      "Batch#19, Score = 73.31966400146484 / 1\n",
      "Batch#20, Score = 71.75636291503906 / 1\n",
      "Batch#21, Score = 71.34366607666016 / 1\n",
      "Batch#22, Score = 72.23123168945312 / 1\n",
      "Batch#23, Score = 74.94921875 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 72.0312\n",
      "epoch# 2\n",
      "score 71.611\n",
      "epoch# 3\n",
      "score 71.6538\n",
      "epoch# 4\n",
      "score 74.1095\n",
      "epoch# 5\n",
      "score 72.1724\n",
      "epoch# 6\n",
      "score 70.0942\n",
      "epoch# 7\n",
      "score 72.5937\n",
      "Fintune has done! Average Score is 0.7203797149658203 / 1\n",
      "Prepare to predict\n",
      "Result: [53, -1.0, 36.287739, -1.0, 35.698296, -1.0, 35.066071, 1.0, 35.495186, 1.0, 37.415329]\n",
      "\n",
      "File# 5 Finetuning\n",
      "Load ./cr2_final_20180608_54.pth\n",
      "epoch# 1\n",
      "score 72.2005\n",
      "Valid: 68.7589\n",
      "epoch# 2\n",
      "score 72.144\n",
      "Valid: 68.9517\n",
      "epoch# 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 71.8223\n",
      "Valid: 67.7643\n",
      "epoch# 4\n",
      "score 72.0175\n",
      "Valid: 69.1821\n",
      "epoch# 5\n",
      "score 72.242\n",
      "Valid: 67.5669\n",
      "epoch# 6\n",
      "score 72.0732\n",
      "Valid: 68.4421\n",
      "epoch# 7\n",
      "score 72.5709\n",
      "Valid: 69.2949\n",
      "epoch# 8\n",
      "score 71.3922\n",
      "Valid: 68.6715\n",
      "epoch# 9\n",
      "score 71.5622\n",
      "Valid: 68.6203\n",
      "epoch# 10\n",
      "score 72.659\n",
      "Valid: 68.5553\n",
      "epoch# 11\n",
      "score 71.6028\n",
      "Valid: 69.2932\n",
      "epoch# 12\n",
      "score 72.4772\n",
      "Valid: 68.7521\n",
      "epoch# 13\n",
      "score 72.8834\n",
      "Valid: 68.6446\n",
      "epoch# 14\n",
      "score 72.1004\n",
      "Valid: 69.0507\n",
      "epoch# 15\n",
      "score 72.3961\n",
      "Valid: 69.7402\n",
      "epoch# 16\n",
      "score 72.4742\n",
      "Valid: 68.9906\n",
      "epoch# 17\n",
      "score 72.355\n",
      "Valid: 70.1893\n",
      "epoch# 18\n",
      "score 71.6875\n",
      "Valid: 68.7592\n",
      "epoch# 19\n",
      "score 72.5664\n",
      "Valid: 68.3579\n",
      "epoch# 20\n",
      "score 72.6082\n",
      "Valid: 69.2129\n",
      "epoch# 21\n",
      "score 72.557\n",
      "Valid: 69.5764\n",
      "epoch# 22\n",
      "score 71.7692\n",
      "Valid: 68.4687\n",
      "epoch# 23\n",
      "score 72.8631\n",
      "Valid: 69.4166\n",
      "epoch# 24\n",
      "score 72.3227\n",
      "Valid: 68.8672\n",
      "epoch# 25\n",
      "score 72.7686\n",
      "Valid: 67.6837\n",
      "epoch# 26\n",
      "score 71.7049\n",
      "Valid: 68.7122\n",
      "epoch# 27\n",
      "score 73.0041\n",
      "Valid: 68.0823\n",
      "Fintune has done! Average Score is 0.7225276947021484 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 54.607818603515625 / 1\n",
      "Batch#1, Score = 67.64552307128906 / 1\n",
      "Batch#2, Score = 52.087135314941406 / 1\n",
      "Batch#3, Score = 68.78679656982422 / 1\n",
      "Batch#4, Score = 51.374473571777344 / 1\n",
      "Batch#5, Score = 68.1822509765625 / 1\n",
      "Batch#6, Score = 67.40509796142578 / 1\n",
      "Batch#7, Score = 72.37950134277344 / 1\n",
      "Batch#8, Score = 63.2493782043457 / 1\n",
      "Batch#9, Score = 63.60460662841797 / 1\n",
      "Batch#10, Score = 63.77954864501953 / 1\n",
      "Batch#11, Score = 80.05703735351562 / 1\n",
      "Batch#12, Score = 64.53511047363281 / 1\n",
      "Batch#13, Score = 66.41494750976562 / 1\n",
      "Batch#14, Score = 70.38575744628906 / 1\n",
      "Batch#15, Score = 73.97914123535156 / 1\n",
      "Batch#16, Score = 87.47093963623047 / 1\n",
      "Batch#17, Score = 81.69938659667969 / 1\n",
      "Batch#18, Score = 63.2314453125 / 1\n",
      "Batch#19, Score = 68.75126647949219 / 1\n",
      "Batch#20, Score = 68.8150405883789 / 1\n",
      "Batch#21, Score = 66.30357360839844 / 1\n",
      "Batch#22, Score = 66.47097778320312 / 1\n",
      "Batch#23, Score = 82.75936126708984 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 68.7845\n",
      "epoch# 2\n",
      "score 69.4087\n",
      "epoch# 3\n",
      "score 69.1354\n",
      "epoch# 4\n",
      "score 68.7164\n",
      "epoch# 5\n",
      "score 69.8707\n",
      "epoch# 6\n",
      "score 69.9184\n",
      "epoch# 7\n",
      "score 70.1688\n",
      "epoch# 8\n",
      "score 68.0615\n",
      "epoch# 9\n",
      "score 69.7579\n",
      "epoch# 10\n",
      "score 69.6748\n",
      "Fintune has done! Average Score is 0.6934969329833984 / 1\n",
      "Prepare to predict\n",
      "Result: [54, -1.0, 24.483486, -1.0, 24.178747, 1.0, 24.961266, 1.0, 25.965378, -1.0, 25.911367]\n",
      "\n",
      "File# 6 Finetuning\n",
      "Load ./cr2_final_20180608_55.pth\n",
      "epoch# 1\n",
      "score 71.8882\n",
      "Valid: 71.8347\n",
      "epoch# 2\n",
      "score 71.9278\n",
      "Valid: 71.1562\n",
      "epoch# 3\n",
      "score 72.0386\n",
      "Valid: 70.5189\n",
      "epoch# 4\n",
      "score 72.3774\n",
      "Valid: 71.7871\n",
      "epoch# 5\n",
      "score 71.6743\n",
      "Valid: 72.3299\n",
      "epoch# 6\n",
      "score 71.833\n",
      "Valid: 71.1607\n",
      "epoch# 7\n",
      "score 72.5569\n",
      "Valid: 70.9369\n",
      "epoch# 8\n",
      "score 71.5628\n",
      "Valid: 69.3365\n",
      "epoch# 9\n",
      "score 71.5742\n",
      "Valid: 69.9404\n",
      "epoch# 10\n",
      "score 71.926\n",
      "Valid: 70.9779\n",
      "epoch# 11\n",
      "score 71.8872\n",
      "Valid: 68.7692\n",
      "epoch# 12\n",
      "score 72.0212\n",
      "Valid: 69.5856\n",
      "epoch# 13\n",
      "score 71.86\n",
      "Valid: 71.9818\n",
      "epoch# 14\n",
      "score 71.9489\n",
      "Valid: 71.2494\n",
      "epoch# 15\n",
      "score 71.9715\n",
      "Valid: 72.3483\n",
      "epoch# 16\n",
      "score 71.8848\n",
      "Valid: 69.6763\n",
      "epoch# 17\n",
      "score 71.5823\n",
      "Valid: 71.7398\n",
      "epoch# 18\n",
      "score 71.6929\n",
      "Valid: 69.4258\n",
      "epoch# 19\n",
      "score 71.9911\n",
      "Valid: 69.453\n",
      "epoch# 20\n",
      "score 71.4889\n",
      "Valid: 71.5382\n",
      "epoch# 21\n",
      "score 72.0738\n",
      "Valid: 68.8297\n",
      "epoch# 22\n",
      "score 72.4271\n",
      "Valid: 71.7403\n",
      "epoch# 23\n",
      "score 71.4786\n",
      "Valid: 71.6172\n",
      "epoch# 24\n",
      "score 72.0065\n",
      "Valid: 69.1811\n",
      "epoch# 25\n",
      "score 71.7013\n",
      "Valid: 72.2241\n",
      "Fintune has done! Average Score is 0.7189501190185547 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 68.3350830078125 / 1\n",
      "Batch#1, Score = 69.92530822753906 / 1\n",
      "Batch#2, Score = 75.73703002929688 / 1\n",
      "Batch#3, Score = 67.58262634277344 / 1\n",
      "Batch#4, Score = 61.053375244140625 / 1\n",
      "Batch#5, Score = 73.83348846435547 / 1\n",
      "Batch#6, Score = 76.6868896484375 / 1\n",
      "Batch#7, Score = 70.84193420410156 / 1\n",
      "Batch#8, Score = 77.18789672851562 / 1\n",
      "Batch#9, Score = 69.83992767333984 / 1\n",
      "Batch#10, Score = 75.06587219238281 / 1\n",
      "Batch#11, Score = 72.6431655883789 / 1\n",
      "Batch#12, Score = 70.24226379394531 / 1\n",
      "Batch#13, Score = 73.26197814941406 / 1\n",
      "Batch#14, Score = 77.93053436279297 / 1\n",
      "Batch#15, Score = 70.37471008300781 / 1\n",
      "Batch#16, Score = 74.30072021484375 / 1\n",
      "Batch#17, Score = 70.79242706298828 / 1\n",
      "Batch#18, Score = 79.9958724975586 / 1\n",
      "Batch#19, Score = 67.43104553222656 / 1\n",
      "Batch#20, Score = 69.3579330444336 / 1\n",
      "Batch#21, Score = 71.30719757080078 / 1\n",
      "Batch#22, Score = 71.51760864257812 / 1\n",
      "Batch#23, Score = 78.13287353515625 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 71.8314\n",
      "epoch# 2\n",
      "score 71.4543\n",
      "epoch# 3\n",
      "score 70.6242\n",
      "epoch# 4\n",
      "score 73.0\n",
      "epoch# 5\n",
      "score 72.5557\n",
      "epoch# 6\n",
      "score 73.1275\n",
      "epoch# 7\n",
      "score 71.426\n",
      "epoch# 8\n",
      "score 71.0867\n",
      "epoch# 9\n",
      "score 71.704\n",
      "Fintune has done! Average Score is 0.7186774444580079 / 1\n",
      "Prepare to predict\n",
      "Result: [55, -1.0, 17.490103, 1.0, 17.719322, -1.0, 17.515829, 1.0, 17.769466, 1.0, 17.967985]\n",
      "\n",
      "File# 7 Finetuning\n",
      "Load ./cr2_final_20180608_56.pth\n",
      "epoch# 1\n",
      "score 73.2657\n",
      "Valid: 71.8439\n",
      "epoch# 2\n",
      "score 73.0671\n",
      "Valid: 71.8934\n",
      "epoch# 3\n",
      "score 72.5962\n",
      "Valid: 72.89\n",
      "epoch# 4\n",
      "score 73.7009\n",
      "Valid: 71.3565\n",
      "epoch# 5\n",
      "score 73.3445\n",
      "Valid: 72.5644\n",
      "epoch# 6\n",
      "score 73.6125\n",
      "Valid: 72.5019\n",
      "epoch# 7\n",
      "score 72.9911\n",
      "Valid: 72.3341\n",
      "epoch# 8\n",
      "score 73.1388\n",
      "Valid: 72.4693\n",
      "epoch# 9\n",
      "score 72.2858\n",
      "Valid: 71.2137\n",
      "epoch# 10\n",
      "score 73.5709\n",
      "Valid: 71.3499\n",
      "epoch# 11\n",
      "score 74.1165\n",
      "Valid: 71.7214\n",
      "epoch# 12\n",
      "score 73.8722\n",
      "Valid: 70.3752\n",
      "epoch# 13\n",
      "score 72.7589\n",
      "Valid: 72.2389\n",
      "Fintune has done! Average Score is 0.7325547790527344 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 73.15275573730469 / 1\n",
      "Batch#1, Score = 63.19200897216797 / 1\n",
      "Batch#2, Score = 64.4216079711914 / 1\n",
      "Batch#3, Score = 72.49603271484375 / 1\n",
      "Batch#4, Score = 72.35926818847656 / 1\n",
      "Batch#5, Score = 68.82196807861328 / 1\n",
      "Batch#6, Score = 74.54802703857422 / 1\n",
      "Batch#7, Score = 73.42678833007812 / 1\n",
      "Batch#8, Score = 70.44640350341797 / 1\n",
      "Batch#9, Score = 74.46045684814453 / 1\n",
      "Batch#10, Score = 75.52891540527344 / 1\n",
      "Batch#11, Score = 73.56888580322266 / 1\n",
      "Batch#12, Score = 71.72899627685547 / 1\n",
      "Batch#13, Score = 73.18549346923828 / 1\n",
      "Batch#14, Score = 74.19273376464844 / 1\n",
      "Batch#15, Score = 72.72593688964844 / 1\n",
      "Batch#16, Score = 80.30345916748047 / 1\n",
      "Batch#17, Score = 78.21089935302734 / 1\n",
      "Batch#18, Score = 71.58247375488281 / 1\n",
      "Batch#19, Score = 69.26316833496094 / 1\n",
      "Batch#20, Score = 70.33872985839844 / 1\n",
      "Batch#21, Score = 70.22444152832031 / 1\n",
      "Batch#22, Score = 70.79983520507812 / 1\n",
      "Batch#23, Score = 74.75308990478516 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 72.207\n",
      "epoch# 2\n",
      "score 72.5961\n",
      "epoch# 3\n",
      "score 73.731\n",
      "epoch# 4\n",
      "score 73.1117\n",
      "epoch# 5\n",
      "score 72.7676\n",
      "epoch# 6\n",
      "score 73.6235\n",
      "Fintune has done! Average Score is 0.7300618743896484 / 1\n",
      "Prepare to predict\n",
      "Result: [56, -1.0, 26.10936, 1.0, 26.869535, -1.0, 26.659676, -1.0, 26.549744, -1.0, 25.921797]\n",
      "\n",
      "File# 8 Finetuning\n",
      "Load ./cr2_final_20180608_57.pth\n",
      "epoch# 1\n",
      "score 71.347\n",
      "Valid: 71.9458\n",
      "epoch# 2\n",
      "score 70.9635\n",
      "Valid: 71.508\n",
      "epoch# 3\n",
      "score 71.5912\n",
      "Valid: 71.1012\n",
      "epoch# 4\n",
      "score 70.3723\n",
      "Valid: 71.2698\n",
      "epoch# 5\n",
      "score 70.3829\n",
      "Valid: 70.5285\n",
      "epoch# 6\n",
      "score 71.0824\n",
      "Valid: 71.6278\n",
      "epoch# 7\n",
      "score 70.7165\n",
      "Valid: 70.6857\n",
      "epoch# 8\n",
      "score 70.5592\n",
      "Valid: 70.6071\n",
      "epoch# 9\n",
      "score 70.4491\n",
      "Valid: 71.3065\n",
      "epoch# 10\n",
      "score 71.1968\n",
      "Valid: 70.4233\n",
      "epoch# 11\n",
      "score 71.0936\n",
      "Valid: 70.576\n",
      "Fintune has done! Average Score is 0.7088677215576172 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 69.63115692138672 / 1\n",
      "Batch#1, Score = 66.5479507446289 / 1\n",
      "Batch#2, Score = 68.81752014160156 / 1\n",
      "Batch#3, Score = 70.25286865234375 / 1\n",
      "Batch#4, Score = 69.3960952758789 / 1\n",
      "Batch#5, Score = 64.11798858642578 / 1\n",
      "Batch#6, Score = 70.61832427978516 / 1\n",
      "Batch#7, Score = 73.2880630493164 / 1\n",
      "Batch#8, Score = 66.39659118652344 / 1\n",
      "Batch#9, Score = 65.82101440429688 / 1\n",
      "Batch#10, Score = 66.94009399414062 / 1\n",
      "Batch#11, Score = 75.85897064208984 / 1\n",
      "Batch#12, Score = 67.67185974121094 / 1\n",
      "Batch#13, Score = 75.06333923339844 / 1\n",
      "Batch#14, Score = 68.12522888183594 / 1\n",
      "Batch#15, Score = 67.98963928222656 / 1\n",
      "Batch#16, Score = 74.03553771972656 / 1\n",
      "Batch#17, Score = 77.97559356689453 / 1\n",
      "Batch#18, Score = 70.40187072753906 / 1\n",
      "Batch#19, Score = 68.16938018798828 / 1\n",
      "Batch#20, Score = 76.58506774902344 / 1\n",
      "Batch#21, Score = 76.25179290771484 / 1\n",
      "Batch#22, Score = 67.71975708007812 / 1\n",
      "Batch#23, Score = 76.1485595703125 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 70.7197\n",
      "epoch# 2\n",
      "score 68.7536\n",
      "epoch# 3\n",
      "score 70.5823\n",
      "epoch# 4\n",
      "score 71.7324\n",
      "epoch# 5\n",
      "score 70.0145\n",
      "epoch# 6\n",
      "score 68.0897\n",
      "epoch# 7\n",
      "score 70.8826\n",
      "Fintune has done! Average Score is 0.7011067962646484 / 1\n",
      "Prepare to predict\n",
      "Result: [57, 1.0, 50.462372, -1.0, 49.686806, 1.0, 50.907005, 1.0, 52.899609, -1.0, 51.724197]\n",
      "\n",
      "File# 9 Finetuning\n",
      "Load ./cr2_final_20180608_58.pth\n",
      "epoch# 1\n",
      "score 67.9861\n",
      "Valid: 69.3283\n",
      "epoch# 2\n",
      "score 68.0158\n",
      "Valid: 70.1664\n",
      "epoch# 3\n",
      "score 67.3215\n",
      "Valid: 69.5238\n",
      "epoch# 4\n",
      "score 67.8784\n",
      "Valid: 69.5252\n",
      "epoch# 5\n",
      "score 67.9835\n",
      "Valid: 69.9972\n",
      "epoch# 6\n",
      "score 67.9211\n",
      "Valid: 70.3111\n",
      "epoch# 7\n",
      "score 67.2682\n",
      "Valid: 70.2927\n",
      "epoch# 8\n",
      "score 67.4923\n",
      "Valid: 69.4902\n",
      "epoch# 9\n",
      "score 68.0213\n",
      "Valid: 70.1576\n",
      "epoch# 10\n",
      "score 67.8932\n",
      "Valid: 69.9544\n",
      "epoch# 11\n",
      "score 68.0228\n",
      "Valid: 69.7531\n",
      "epoch# 12\n",
      "score 67.2164\n",
      "Valid: 70.4423\n",
      "epoch# 13\n",
      "score 67.5457\n",
      "Valid: 69.348\n",
      "epoch# 14\n",
      "score 68.0842\n",
      "Valid: 69.9771\n",
      "epoch# 15\n",
      "score 67.7418\n",
      "Valid: 69.5121\n",
      "epoch# 16\n",
      "score 68.3732\n",
      "Valid: 69.8457\n",
      "epoch# 17\n",
      "score 67.4094\n",
      "Valid: 69.4994\n",
      "epoch# 18\n",
      "score 68.0101\n",
      "Valid: 69.9355\n",
      "epoch# 19\n",
      "score 67.6161\n",
      "Valid: 69.9166\n",
      "epoch# 20\n",
      "score 67.7371\n",
      "Valid: 69.5355\n",
      "epoch# 21\n",
      "score 68.07\n",
      "Valid: 70.4768\n",
      "epoch# 22\n",
      "score 67.3317\n",
      "Valid: 69.635\n",
      "epoch# 23\n",
      "score 67.3978\n",
      "Valid: 69.5244\n",
      "epoch# 24\n",
      "score 68.062\n",
      "Valid: 69.6502\n",
      "epoch# 25\n",
      "score 67.6937\n",
      "Valid: 69.79\n",
      "epoch# 26\n",
      "score 67.6381\n",
      "Valid: 70.1995\n",
      "epoch# 27\n",
      "score 67.5355\n",
      "Valid: 69.5655\n",
      "epoch# 28\n",
      "score 67.8527\n",
      "Valid: 70.3406\n",
      "epoch# 29\n",
      "score 67.6024\n",
      "Valid: 70.1071\n",
      "epoch# 30\n",
      "score 67.573\n",
      "Valid: 69.5856\n",
      "epoch# 31\n",
      "score 67.6472\n",
      "Valid: 69.615\n",
      "Fintune has done! Average Score is 0.6774008178710937 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 65.4132308959961 / 1\n",
      "Batch#1, Score = 64.92799377441406 / 1\n",
      "Batch#2, Score = 67.8381118774414 / 1\n",
      "Batch#3, Score = 66.87144470214844 / 1\n",
      "Batch#4, Score = 70.48678588867188 / 1\n",
      "Batch#5, Score = 72.39299774169922 / 1\n",
      "Batch#6, Score = 62.40392303466797 / 1\n",
      "Batch#7, Score = 71.25212097167969 / 1\n",
      "Batch#8, Score = 67.90645599365234 / 1\n",
      "Batch#9, Score = 70.6493911743164 / 1\n",
      "Batch#10, Score = 71.49046325683594 / 1\n",
      "Batch#11, Score = 72.4012222290039 / 1\n",
      "Batch#12, Score = 68.358642578125 / 1\n",
      "Batch#13, Score = 63.825801849365234 / 1\n",
      "Batch#14, Score = 74.0355224609375 / 1\n",
      "Batch#15, Score = 68.28105163574219 / 1\n",
      "Batch#16, Score = 58.88569259643555 / 1\n",
      "Batch#17, Score = 73.9708023071289 / 1\n",
      "Batch#18, Score = 77.44351196289062 / 1\n",
      "Batch#19, Score = 66.33695983886719 / 1\n",
      "Batch#20, Score = 76.96919250488281 / 1\n",
      "Batch#21, Score = 72.4391098022461 / 1\n",
      "Batch#22, Score = 76.36934661865234 / 1\n",
      "Batch#23, Score = 69.81148529052734 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 68.0494\n",
      "epoch# 2\n",
      "score 68.8046\n",
      "epoch# 3\n",
      "score 68.8424\n",
      "epoch# 4\n",
      "score 68.4573\n",
      "epoch# 5\n",
      "score 69.6363\n",
      "epoch# 6\n",
      "score 69.6601\n",
      "epoch# 7\n",
      "score 68.5748\n",
      "epoch# 8\n",
      "score 68.7522\n",
      "epoch# 9\n",
      "score 68.9158\n",
      "Fintune has done! Average Score is 0.6885476684570313 / 1\n",
      "Prepare to predict\n",
      "Result: [58, 1.0, 47.751801, -1.0, 47.407806, 1.0, 50.353546, -1.0, 49.948147, -1.0, 48.850864]\n",
      "\n",
      "File# 10 Finetuning\n",
      "Load ./cr2_final_20180608_59.pth\n",
      "epoch# 1\n",
      "score 68.3292\n",
      "Valid: 70.5542\n",
      "epoch# 2\n",
      "score 68.1819\n",
      "Valid: 72.8169\n",
      "epoch# 3\n",
      "score 67.9281\n",
      "Valid: 71.5773\n",
      "epoch# 4\n",
      "score 67.8557\n",
      "Valid: 70.1145\n",
      "epoch# 5\n",
      "score 67.9334\n",
      "Valid: 70.1551\n",
      "epoch# 6\n",
      "score 68.2561\n",
      "Valid: 69.9869\n",
      "epoch# 7\n",
      "score 68.352\n",
      "Valid: 71.2427\n",
      "epoch# 8\n",
      "score 68.6148\n",
      "Valid: 72.2263\n",
      "epoch# 9\n",
      "score 68.4623\n",
      "Valid: 69.3533\n",
      "epoch# 10\n",
      "score 68.1248\n",
      "Valid: 70.6242\n",
      "epoch# 11\n",
      "score 68.0509\n",
      "Valid: 70.6652\n",
      "epoch# 12\n",
      "score 67.7808\n",
      "Valid: 70.9977\n",
      "Fintune has done! Average Score is 0.6815582275390625 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 64.8288345336914 / 1\n",
      "Batch#1, Score = 68.12186431884766 / 1\n",
      "Batch#2, Score = 65.09495544433594 / 1\n",
      "Batch#3, Score = 75.88459777832031 / 1\n",
      "Batch#4, Score = 71.6324462890625 / 1\n",
      "Batch#5, Score = 70.91626739501953 / 1\n",
      "Batch#6, Score = 70.72185516357422 / 1\n",
      "Batch#7, Score = 76.4466323852539 / 1\n",
      "Batch#8, Score = 69.39674377441406 / 1\n",
      "Batch#9, Score = 75.95712280273438 / 1\n",
      "Batch#10, Score = 71.57829284667969 / 1\n",
      "Batch#11, Score = 74.02857971191406 / 1\n",
      "Batch#12, Score = 68.94576263427734 / 1\n",
      "Batch#13, Score = 70.48772430419922 / 1\n",
      "Batch#14, Score = 67.5218734741211 / 1\n",
      "Batch#15, Score = 69.80329895019531 / 1\n",
      "Batch#16, Score = 72.22886657714844 / 1\n",
      "Batch#17, Score = 73.4740982055664 / 1\n",
      "Batch#18, Score = 71.21998596191406 / 1\n",
      "Batch#19, Score = 74.71138763427734 / 1\n",
      "Batch#20, Score = 65.4001235961914 / 1\n",
      "Batch#21, Score = 66.39620208740234 / 1\n",
      "Batch#22, Score = 78.9678955078125 / 1\n",
      "Batch#23, Score = 70.1800308227539 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 69.9372\n",
      "epoch# 2\n",
      "score 71.011\n",
      "epoch# 3\n",
      "score 68.7925\n",
      "epoch# 4\n",
      "score 69.5323\n",
      "epoch# 5\n",
      "score 70.6129\n",
      "Fintune has done! Average Score is 0.6997718811035156 / 1\n",
      "Prepare to predict\n",
      "Result: [59, -1.0, 42.632973, 1.0, 43.536758, 1.0, 43.793674, 1.0, 45.206303, -1.0, 43.556534]\n",
      "\n",
      "File# 11 Finetuning\n",
      "Load ./cr2_final_20180608_6201.pth\n",
      "epoch# 1\n",
      "score 71.8743\n",
      "Valid: 72.3003\n",
      "epoch# 2\n",
      "score 72.242\n",
      "Valid: 71.8423\n",
      "epoch# 3\n",
      "score 71.8755\n",
      "Valid: 70.9895\n",
      "epoch# 4\n",
      "score 71.646\n",
      "Valid: 70.7973\n",
      "epoch# 5\n",
      "score 72.0477\n",
      "Valid: 70.5715\n",
      "epoch# 6\n",
      "score 72.1191\n",
      "Valid: 70.8885\n",
      "epoch# 7\n",
      "score 72.1308\n",
      "Valid: 71.8994\n",
      "epoch# 8\n",
      "score 72.2229\n",
      "Valid: 71.8332\n",
      "epoch# 9\n",
      "score 72.1504\n",
      "Valid: 70.5861\n",
      "epoch# 10\n",
      "score 72.3905\n",
      "Valid: 70.6002\n",
      "epoch# 11\n",
      "score 71.8418\n",
      "Valid: 70.6063\n",
      "Fintune has done! Average Score is 0.7204917907714844 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 68.59640502929688 / 1\n",
      "Batch#1, Score = 73.64018249511719 / 1\n",
      "Batch#2, Score = 58.096893310546875 / 1\n",
      "Batch#3, Score = 78.95896911621094 / 1\n",
      "Batch#4, Score = 72.08574676513672 / 1\n",
      "Batch#5, Score = 79.17174530029297 / 1\n",
      "Batch#6, Score = 72.90962219238281 / 1\n",
      "Batch#7, Score = 80.89971923828125 / 1\n",
      "Batch#8, Score = 62.79213333129883 / 1\n",
      "Batch#9, Score = 72.88350677490234 / 1\n",
      "Batch#10, Score = 62.66115188598633 / 1\n",
      "Batch#11, Score = 57.38080978393555 / 1\n",
      "Batch#12, Score = 70.7675552368164 / 1\n",
      "Batch#13, Score = 71.53177642822266 / 1\n",
      "Batch#14, Score = 69.27120208740234 / 1\n",
      "Batch#15, Score = 71.32502746582031 / 1\n",
      "Batch#16, Score = 84.48973846435547 / 1\n",
      "Batch#17, Score = 73.80734252929688 / 1\n",
      "Batch#18, Score = 62.6368408203125 / 1\n",
      "Batch#19, Score = 71.4653549194336 / 1\n",
      "Batch#20, Score = 67.3790283203125 / 1\n",
      "Batch#21, Score = 69.84724426269531 / 1\n",
      "Batch#22, Score = 68.58047485351562 / 1\n",
      "Batch#23, Score = 73.37313079833984 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 69.9072\n",
      "epoch# 2\n",
      "score 70.7043\n",
      "epoch# 3\n",
      "score 71.7085\n",
      "epoch# 4\n",
      "score 70.9052\n",
      "epoch# 5\n",
      "score 71.8452\n",
      "epoch# 6\n",
      "score 70.984\n",
      "epoch# 7\n",
      "score 69.9839\n",
      "epoch# 8\n",
      "score 71.0691\n",
      "Fintune has done! Average Score is 0.7088844299316406 / 1\n",
      "Prepare to predict\n",
      "Result: [6201, -1.0, 14.240335, 1.0, 14.557272, -1.0, 14.532419, 1.0, 14.680979, -1.0, 14.380525]\n",
      "\n",
      "File# 12 Finetuning\n",
      "Load ./cr2_final_20180608_6203.pth\n",
      "epoch# 1\n",
      "score 66.1305\n",
      "Valid: 70.28\n",
      "epoch# 2\n",
      "score 66.7222\n",
      "Valid: 69.3039\n",
      "epoch# 3\n",
      "score 67.1263\n",
      "Valid: 69.6718\n",
      "epoch# 4\n",
      "score 66.9442\n",
      "Valid: 69.5544\n",
      "epoch# 5\n",
      "score 67.2191\n",
      "Valid: 69.5397\n",
      "epoch# 6\n",
      "score 67.3285\n",
      "Valid: 70.1147\n",
      "epoch# 7\n",
      "score 66.897\n",
      "Valid: 69.5267\n",
      "epoch# 8\n",
      "score 67.2313\n",
      "Valid: 69.4103\n",
      "epoch# 9\n",
      "score 66.9869\n",
      "Valid: 68.8311\n",
      "epoch# 10\n",
      "score 66.8526\n",
      "Valid: 70.1565\n",
      "epoch# 11\n",
      "score 66.6493\n",
      "Valid: 69.8893\n",
      "Fintune has done! Average Score is 0.6691708374023437 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 58.721351623535156 / 1\n",
      "Batch#1, Score = 68.28765106201172 / 1\n",
      "Batch#2, Score = 71.72402954101562 / 1\n",
      "Batch#3, Score = 60.112876892089844 / 1\n",
      "Batch#4, Score = 77.79476165771484 / 1\n",
      "Batch#5, Score = 62.57871627807617 / 1\n",
      "Batch#6, Score = 71.33551788330078 / 1\n",
      "Batch#7, Score = 70.48771667480469 / 1\n",
      "Batch#8, Score = 79.1572494506836 / 1\n",
      "Batch#9, Score = 64.03414916992188 / 1\n",
      "Batch#10, Score = 75.89884948730469 / 1\n",
      "Batch#11, Score = 68.07069396972656 / 1\n",
      "Batch#12, Score = 69.70556640625 / 1\n",
      "Batch#13, Score = 67.23116302490234 / 1\n",
      "Batch#14, Score = 75.26145935058594 / 1\n",
      "Batch#15, Score = 63.72114944458008 / 1\n",
      "Batch#16, Score = 61.170372009277344 / 1\n",
      "Batch#17, Score = 71.75572204589844 / 1\n",
      "Batch#18, Score = 80.00242614746094 / 1\n",
      "Batch#19, Score = 63.94389724731445 / 1\n",
      "Batch#20, Score = 80.7770767211914 / 1\n",
      "Batch#21, Score = 72.26471710205078 / 1\n",
      "Batch#22, Score = 75.33936309814453 / 1\n",
      "Batch#23, Score = 67.48627471923828 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 70.0923\n",
      "epoch# 2\n",
      "score 68.8239\n",
      "epoch# 3\n",
      "score 69.5893\n",
      "epoch# 4\n",
      "score 68.284\n",
      "Fintune has done! Average Score is 0.6919740295410156 / 1\n",
      "Prepare to predict\n",
      "Result: [6203, -1.0, 37.936348, 1.0, 38.759789, 1.0, 39.373451, -1.0, 38.466057, 1.0, 39.246765]\n",
      "\n",
      "File# 13 Finetuning\n",
      "Load ./cr2_final_20180608_6204.pth\n",
      "epoch# 1\n",
      "score 68.0815\n",
      "Valid: 68.1698\n",
      "epoch# 2\n",
      "score 67.7712\n",
      "Valid: 69.7129\n",
      "epoch# 3\n",
      "score 67.6276\n",
      "Valid: 69.8406\n",
      "epoch# 4\n",
      "score 68.0163\n",
      "Valid: 67.5579\n",
      "epoch# 5\n",
      "score 68.7301\n",
      "Valid: 68.1107\n",
      "epoch# 6\n",
      "score 67.7322\n",
      "Valid: 67.467\n",
      "epoch# 7\n",
      "score 67.825\n",
      "Valid: 67.9883\n",
      "epoch# 8\n",
      "score 67.213\n",
      "Valid: 69.4602\n",
      "epoch# 9\n",
      "score 68.2139\n",
      "Valid: 68.3247\n",
      "epoch# 10\n",
      "score 68.0187\n",
      "Valid: 68.3335\n",
      "epoch# 11\n",
      "score 67.8981\n",
      "Valid: 68.504\n",
      "epoch# 12\n",
      "score 67.3393\n",
      "Valid: 68.8358\n",
      "epoch# 13\n",
      "score 67.9537\n",
      "Valid: 67.1346\n",
      "Fintune has done! Average Score is 0.6787850952148438 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 58.51042938232422 / 1\n",
      "Batch#1, Score = 69.71903991699219 / 1\n",
      "Batch#2, Score = 64.78629302978516 / 1\n",
      "Batch#3, Score = 63.44620895385742 / 1\n",
      "Batch#4, Score = 61.11318588256836 / 1\n",
      "Batch#5, Score = 67.669677734375 / 1\n",
      "Batch#6, Score = 68.7402572631836 / 1\n",
      "Batch#7, Score = 73.47853088378906 / 1\n",
      "Batch#8, Score = 70.24381256103516 / 1\n",
      "Batch#9, Score = 69.0041732788086 / 1\n",
      "Batch#10, Score = 60.6431999206543 / 1\n",
      "Batch#11, Score = 69.86502838134766 / 1\n",
      "Batch#12, Score = 69.33180236816406 / 1\n",
      "Batch#13, Score = 65.7974624633789 / 1\n",
      "Batch#14, Score = 63.03986358642578 / 1\n",
      "Batch#15, Score = 58.682029724121094 / 1\n",
      "Batch#16, Score = 70.44264221191406 / 1\n",
      "Batch#17, Score = 66.61970520019531 / 1\n",
      "Batch#18, Score = 69.06166076660156 / 1\n",
      "Batch#19, Score = 70.7655029296875 / 1\n",
      "Batch#20, Score = 71.87754821777344 / 1\n",
      "Batch#21, Score = 72.75118255615234 / 1\n",
      "Batch#22, Score = 65.27433013916016 / 1\n",
      "Batch#23, Score = 71.17375183105469 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 69.3192\n",
      "epoch# 2\n",
      "score 69.36\n",
      "epoch# 3\n",
      "score 68.9234\n",
      "epoch# 4\n",
      "score 70.4543\n",
      "epoch# 5\n",
      "score 68.8892\n",
      "epoch# 6\n",
      "score 69.4799\n",
      "epoch# 7\n",
      "score 69.4621\n",
      "Fintune has done! Average Score is 0.6941258239746094 / 1\n",
      "Prepare to predict\n",
      "Result: [6204, -1.0, 55.028511, 1.0, 55.716, -1.0, 54.206142, 1.0, 56.032597, 1.0, 56.156998]\n",
      "\n",
      "File# 14 Finetuning\n",
      "Load ./cr2_final_20180608_6208.pth\n",
      "epoch# 1\n",
      "score 68.0058\n",
      "Valid: 70.3904\n",
      "epoch# 2\n",
      "score 67.9\n",
      "Valid: 70.6642\n",
      "epoch# 3\n",
      "score 68.649\n",
      "Valid: 70.5724\n",
      "epoch# 4\n",
      "score 67.9306\n",
      "Valid: 70.399\n",
      "epoch# 5\n",
      "score 67.9001\n",
      "Valid: 70.0704\n",
      "epoch# 6\n",
      "score 68.0389\n",
      "Valid: 69.6747\n",
      "epoch# 7\n",
      "score 67.6677\n",
      "Valid: 70.0767\n",
      "epoch# 8\n",
      "score 67.4284\n",
      "Valid: 70.4161\n",
      "epoch# 9\n",
      "score 67.5811\n",
      "Valid: 70.2016\n",
      "epoch# 10\n",
      "score 67.1753\n",
      "Valid: 70.644\n",
      "epoch# 11\n",
      "score 68.1088\n",
      "Valid: 70.7022\n",
      "epoch# 12\n",
      "score 67.9632\n",
      "Valid: 70.6171\n",
      "epoch# 13\n",
      "score 67.8047\n",
      "Valid: 70.1326\n",
      "epoch# 14\n",
      "score 67.9202\n",
      "Valid: 70.088\n",
      "epoch# 15\n",
      "score 68.011\n",
      "Valid: 70.2724\n",
      "epoch# 16\n",
      "score 68.1768\n",
      "Valid: 70.2959\n",
      "epoch# 17\n",
      "score 67.301\n",
      "Valid: 70.1193\n",
      "epoch# 18\n",
      "score 67.623\n",
      "Valid: 69.5869\n",
      "epoch# 19\n",
      "score 68.0203\n",
      "Valid: 70.6314\n",
      "epoch# 20\n",
      "score 68.1925\n",
      "Valid: 69.3755\n",
      "epoch# 21\n",
      "score 67.8347\n",
      "Valid: 70.8524\n",
      "epoch# 22\n",
      "score 67.9401\n",
      "Valid: 71.0431\n",
      "epoch# 23\n",
      "score 67.8914\n",
      "Valid: 69.2347\n",
      "epoch# 24\n",
      "score 68.0406\n",
      "Valid: 70.5169\n",
      "epoch# 25\n",
      "score 68.098\n",
      "Valid: 70.3023\n",
      "epoch# 26\n",
      "score 68.4006\n",
      "Valid: 70.4352\n",
      "epoch# 27\n",
      "score 67.8426\n",
      "Valid: 70.7044\n",
      "epoch# 28\n",
      "score 68.0783\n",
      "Valid: 70.1568\n",
      "epoch# 29\n",
      "score 68.6745\n",
      "Valid: 70.3574\n",
      "epoch# 30\n",
      "score 67.717\n",
      "Valid: 70.8544\n",
      "epoch# 31\n",
      "score 68.1777\n",
      "Valid: 70.6481\n",
      "epoch# 32\n",
      "score 68.2504\n",
      "Valid: 70.8624\n",
      "Fintune has done! Average Score is 0.6794825744628906 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 64.66159057617188 / 1\n",
      "Batch#1, Score = 66.68637084960938 / 1\n",
      "Batch#2, Score = 62.9954719543457 / 1\n",
      "Batch#3, Score = 70.71662139892578 / 1\n",
      "Batch#4, Score = 58.63152313232422 / 1\n",
      "Batch#5, Score = 63.29163360595703 / 1\n",
      "Batch#6, Score = 75.47200012207031 / 1\n",
      "Batch#7, Score = 74.47967529296875 / 1\n",
      "Batch#8, Score = 66.87748718261719 / 1\n",
      "Batch#9, Score = 76.00507354736328 / 1\n",
      "Batch#10, Score = 64.53633117675781 / 1\n",
      "Batch#11, Score = 74.87344360351562 / 1\n",
      "Batch#12, Score = 77.69902038574219 / 1\n",
      "Batch#13, Score = 76.05975341796875 / 1\n",
      "Batch#14, Score = 67.23763275146484 / 1\n",
      "Batch#15, Score = 65.5661392211914 / 1\n",
      "Batch#16, Score = 84.94744873046875 / 1\n",
      "Batch#17, Score = 84.04095458984375 / 1\n",
      "Batch#18, Score = 65.03465270996094 / 1\n",
      "Batch#19, Score = 76.08270263671875 / 1\n",
      "Batch#20, Score = 69.68510437011719 / 1\n",
      "Batch#21, Score = 75.46559143066406 / 1\n",
      "Batch#22, Score = 66.02555084228516 / 1\n",
      "Batch#23, Score = 73.62669372558594 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 70.2769\n",
      "epoch# 2\n",
      "score 69.782\n",
      "epoch# 3\n",
      "score 70.9529\n",
      "epoch# 4\n",
      "score 70.4019\n",
      "epoch# 5\n",
      "score 70.1208\n",
      "epoch# 6\n",
      "score 69.2243\n",
      "Fintune has done! Average Score is 0.7012647247314453 / 1\n",
      "Prepare to predict\n",
      "Result: [6208, 1.0, 48.123882, 1.0, 48.494038, -1.0, 48.166985, 1.0, 48.515003, 1.0, 49.263302]\n",
      "\n",
      "File# 15 Finetuning\n",
      "Load ./cr2_final_20180608_690.pth\n",
      "epoch# 1\n",
      "score 73.6121\n",
      "Valid: 74.584\n",
      "epoch# 2\n",
      "score 72.9412\n",
      "Valid: 75.0647\n",
      "epoch# 3\n",
      "score 74.6332\n",
      "Valid: 73.9126\n",
      "epoch# 4\n",
      "score 72.4391\n",
      "Valid: 75.44\n",
      "epoch# 5\n",
      "score 74.1999\n",
      "Valid: 75.5735\n",
      "epoch# 6\n",
      "score 73.2822\n",
      "Valid: 73.8382\n",
      "epoch# 7\n",
      "score 74.1157\n",
      "Valid: 76.9199\n",
      "epoch# 8\n",
      "score 74.5655\n",
      "Valid: 74.0518\n",
      "epoch# 9\n",
      "score 72.6692\n",
      "Valid: 75.5499\n",
      "epoch# 10\n",
      "score 73.2776\n",
      "Valid: 74.0555\n",
      "epoch# 11\n",
      "score 74.1878\n",
      "Valid: 73.4595\n",
      "epoch# 12\n",
      "score 73.7842\n",
      "Valid: 73.9473\n",
      "epoch# 13\n",
      "score 75.0903\n",
      "Valid: 73.6527\n",
      "epoch# 14\n",
      "score 74.0843\n",
      "Valid: 74.1944\n",
      "epoch# 15\n",
      "score 72.5427\n",
      "Valid: 73.8795\n",
      "epoch# 16\n",
      "score 73.1976\n",
      "Valid: 73.8637\n",
      "epoch# 17\n",
      "score 73.6807\n",
      "Valid: 75.589\n",
      "Fintune has done! Average Score is 0.7366490173339844 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 74.18316650390625 / 1\n",
      "Batch#1, Score = 79.67376708984375 / 1\n",
      "Batch#2, Score = 74.25614929199219 / 1\n",
      "Batch#3, Score = 68.85807800292969 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 74.8123\n",
      "epoch# 2\n",
      "score 73.7022\n",
      "epoch# 3\n",
      "score 75.5448\n",
      "epoch# 4\n",
      "score 74.727\n",
      "epoch# 5\n",
      "score 71.8732\n",
      "epoch# 6\n",
      "score 73.575\n",
      "Fintune has done! Average Score is 0.7403908538818359 / 1\n",
      "Prepare to predict\n",
      "Result: [690, -1.0, 22.129917, -1.0, 21.886438, 1.0, 22.833178, 1.0, 23.160856, -1.0, 22.809673]\n",
      "\n",
      "File# 16 Finetuning\n",
      "Load ./cr2_final_20180608_692.pth\n",
      "epoch# 1\n",
      "score 72.5955\n",
      "Valid: 70.8679\n",
      "epoch# 2\n",
      "score 73.5647\n",
      "Valid: 72.6579\n",
      "epoch# 3\n",
      "score 73.4708\n",
      "Valid: 71.0321\n",
      "epoch# 4\n",
      "score 73.4024\n",
      "Valid: 71.7527\n",
      "epoch# 5\n",
      "score 76.1723\n",
      "Valid: 70.8004\n",
      "epoch# 6\n",
      "score 73.8974\n",
      "Valid: 71.0618\n",
      "epoch# 7\n",
      "score 74.1433\n",
      "Valid: 71.845\n",
      "epoch# 8\n",
      "score 72.2456\n",
      "Valid: 70.9855\n",
      "epoch# 9\n",
      "score 74.1034\n",
      "Valid: 71.6035\n",
      "epoch# 10\n",
      "score 73.4985\n",
      "Valid: 70.3437\n",
      "epoch# 11\n",
      "score 74.7317\n",
      "Valid: 71.9105\n",
      "epoch# 12\n",
      "score 75.1485\n",
      "Valid: 70.2193\n",
      "Fintune has done! Average Score is 0.7391450500488281 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 73.37890625 / 1\n",
      "Batch#1, Score = 70.1068115234375 / 1\n",
      "Batch#2, Score = 65.14063262939453 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 71.7949\n",
      "epoch# 2\n",
      "score 69.9022\n",
      "epoch# 3\n",
      "score 66.8044\n",
      "epoch# 4\n",
      "score 73.9357\n",
      "epoch# 5\n",
      "score 70.9648\n",
      "epoch# 6\n",
      "score 68.4011\n",
      "epoch# 7\n",
      "score 69.6182\n",
      "Fintune has done! Average Score is 0.7020304870605468 / 1\n",
      "Prepare to predict\n",
      "Result: [692, 1.0, 21.210012, 1.0, 21.613646, -1.0, 21.501272, -1.0, 21.33288, -1.0, 20.856987]\n",
      "\n",
      "File# 17 Finetuning\n",
      "Load ./cr2_final_20180608_701.pth\n",
      "epoch# 1\n",
      "score 71.5872\n",
      "Valid: 71.887\n",
      "epoch# 2\n",
      "score 71.2865\n",
      "Valid: 72.1941\n",
      "epoch# 3\n",
      "score 71.5845\n",
      "Valid: 71.4522\n",
      "epoch# 4\n",
      "score 71.6334\n",
      "Valid: 69.5489\n",
      "epoch# 5\n",
      "score 72.2263\n",
      "Valid: 67.1302\n",
      "epoch# 6\n",
      "score 70.6534\n",
      "Valid: 73.4753\n",
      "epoch# 7\n",
      "score 72.4024\n",
      "Valid: 71.7061\n",
      "epoch# 8\n",
      "score 73.7015\n",
      "Valid: 69.296\n",
      "epoch# 9\n",
      "score 73.4647\n",
      "Valid: 69.5147\n",
      "epoch# 10\n",
      "score 71.6443\n",
      "Valid: 70.2976\n",
      "epoch# 11\n",
      "score 70.1591\n",
      "Valid: 71.9929\n",
      "epoch# 12\n",
      "score 70.9123\n",
      "Valid: 68.2663\n",
      "epoch# 13\n",
      "score 71.8685\n",
      "Valid: 72.0079\n",
      "epoch# 14\n",
      "score 71.3463\n",
      "Valid: 69.6883\n",
      "epoch# 15\n",
      "score 71.4551\n",
      "Valid: 72.0221\n",
      "epoch# 16\n",
      "score 72.5824\n",
      "Valid: 69.5208\n",
      "Fintune has done! Average Score is 0.7178173828125 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 72.56917572021484 / 1\n",
      "Batch#1, Score = 54.279136657714844 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 69.3853\n",
      "epoch# 2\n",
      "score 67.7299\n",
      "epoch# 3\n",
      "score 74.3564\n",
      "epoch# 4\n",
      "score 70.2476\n",
      "epoch# 5\n",
      "score 65.7728\n",
      "epoch# 6\n",
      "score 73.8733\n",
      "Fintune has done! Average Score is 0.7022755432128907 / 1\n",
      "Prepare to predict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [701, -1.0, 21.078434, 1.0, 21.284033, -1.0, 20.992483, 1.0, 21.172592, 1.0, 21.504948]\n",
      "\n",
      "File# 18 Finetuning\n",
      "Load ./cr2_final_20180608_713.pth\n",
      "epoch# 1\n",
      "score 70.7543\n",
      "Valid: 73.6471\n",
      "epoch# 2\n",
      "score 69.0072\n",
      "Valid: 71.2354\n",
      "epoch# 3\n",
      "score 70.0739\n",
      "Valid: 76.3359\n",
      "epoch# 4\n",
      "score 68.0327\n",
      "Valid: 80.3347\n",
      "epoch# 5\n",
      "score 70.7557\n",
      "Valid: 82.9208\n",
      "epoch# 6\n",
      "score 70.6324\n",
      "Valid: 80.5066\n",
      "epoch# 7\n",
      "score 68.7747\n",
      "Valid: 79.4898\n",
      "epoch# 8\n",
      "score 69.3065\n",
      "Valid: 80.5014\n",
      "epoch# 9\n",
      "score 69.8704\n",
      "Valid: 82.8934\n",
      "epoch# 10\n",
      "score 69.2997\n",
      "Valid: 75.3243\n",
      "epoch# 11\n",
      "score 67.4421\n",
      "Valid: 70.6163\n",
      "epoch# 12\n",
      "score 67.9355\n",
      "Valid: 78.0781\n",
      "epoch# 13\n",
      "score 67.762\n",
      "Valid: 68.9538\n",
      "epoch# 14\n",
      "score 69.6113\n",
      "Valid: 73.6465\n",
      "epoch# 15\n",
      "score 70.6026\n",
      "Valid: 70.5682\n",
      "Fintune has done! Average Score is 0.6932408142089844 / 1\n",
      "Valid Model...\n",
      "Batch#0, Score = 70.56820678710938 / 1\n",
      "Fintune again for predict next week...\n",
      "epoch# 1\n",
      "score 67.1105\n",
      "epoch# 2\n",
      "score 76.3505\n",
      "epoch# 3\n",
      "score 77.1998\n",
      "epoch# 4\n",
      "score 73.7549\n",
      "epoch# 5\n",
      "score 78.0087\n",
      "epoch# 6\n",
      "score 70.3384\n",
      "epoch# 7\n",
      "score 78.7228\n",
      "epoch# 8\n",
      "score 71.2517\n",
      "epoch# 9\n",
      "score 67.2129\n",
      "epoch# 10\n",
      "score 77.9767\n",
      "Fintune has done! Average Score is 0.7379267883300781 / 1\n",
      "Prepare to predict\n",
      "Result: [713, -1.0, 30.562799, 1.0, 30.849129, 1.0, 31.001945, -1.0, 30.436737, 1.0, 30.651403]\n"
     ]
    }
   ],
   "source": [
    "Result = []\n",
    "for i_file in range(len(finetune_tr_dl)):\n",
    "    print(\"\\nFile#\", i_file + 1, \"Finetuning\")\n",
    "    try:\n",
    "        net.load_state_dict(torch.load(\"./cr2_final_{}_{}.pth\".format(date_list[-6],code_uq[i_file])))\n",
    "        print(\"Load\", \"./cr2_final_{}_{}.pth\".format(date_list[-6],code_uq[i_file]))\n",
    "        trEPOCH = 100\n",
    "        teEPOCH = 200\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        net.load_state_dict(torch.load(\"./cr2.pth\"))\n",
    "        print(\"Load Base\")\n",
    "        trEPOCH = 300\n",
    "        teEPOCH = 400\n",
    "    \n",
    "    op = torch.optim.Adam(net.parameters(), lr=Learning_Rate)\n",
    "    epo_score = []\n",
    "    max_va = -1e9\n",
    "    no_up = 0\n",
    "    for epo in range(trEPOCH):\n",
    "        print(\"epoch#\", epo + 1)\n",
    "        scores = []\n",
    "        for i_batch, sample_batched in enumerate(finetune_tr_dl[i_file]):\n",
    "            for mini_batch in range(sample_batched['X'].size()[0]):\n",
    "                x = var(sample_batched['X'][mini_batch]).cuda()\n",
    "                val = var(sample_batched['close'][mini_batch]).cuda()\n",
    "                updn, ans = net(x, val)\n",
    "                op.zero_grad()\n",
    "\n",
    "                y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][0 + 6]]])).cuda()\n",
    "                y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + 0] - sample_batched['Y'][mini_batch][5 + 0 + 0]])))).view(1,1,-1).cuda()\n",
    "                score = w[0] * (50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3))\n",
    "                loss = lf3((50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3)).view(1, -1), _100.view(1, -1))\n",
    "                for i_sm in range(1, 5):\n",
    "                    y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][i_sm + 6]]])).cuda()\n",
    "                    y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + i_sm] - sample_batched['Y'][mini_batch][5 + 0 + i_sm]])))).view(1,1,-1).cuda()\n",
    "                    score += w[i_sm] * (50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3))\n",
    "                    loss += lf3((50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3)).view(1, -1), _100.view(1, -1))\n",
    "\n",
    "                loss.backward(retain_graph = True)\n",
    "                op.step()\n",
    "                scores.append(score.cpu().data.numpy()[0])\n",
    "                cuda.empty_cache()\n",
    "        epo_score.append(np.average(scores))\n",
    "        print(\"score\", epo_score[-1])\n",
    "        valid_tmp = []\n",
    "        for i_batch, sample_batched in enumerate(finetune_te_dl[i_file]):\n",
    "            for mini_batch in range(sample_batched['X'].size()[0]):\n",
    "                x = var(sample_batched['X'][mini_batch]).cuda()\n",
    "                val = var(sample_batched['close'][mini_batch]).cuda()\n",
    "                updn, ans = net(x, val)\n",
    "\n",
    "                y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][0 + 6]]])).cuda()\n",
    "                y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + 0] - sample_batched['Y'][mini_batch][5 + 0 + 0]])))).view(1,1,-1).cuda()\n",
    "                score = w[0] * (50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3))\n",
    "                for i_sm in range(1, 5):\n",
    "                    y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][i_sm + 6]]])).cuda()\n",
    "                    y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + i_sm] - sample_batched['Y'][mini_batch][5 + 0 + i_sm]])))).view(1,1,-1).cuda()\n",
    "                    score += w[i_sm] * (50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3))\n",
    "\n",
    "                valid_tmp.append(score.cpu().data.numpy()[0])\n",
    "                \n",
    "        print(\"Valid:\", np.average(valid_tmp))\n",
    "        if np.average(valid_tmp) > max_va:\n",
    "            no_up = 0\n",
    "            max_va = np.average(valid_tmp)\n",
    "        else:\n",
    "            no_up += 1\n",
    "            \n",
    "        if no_up >= 10:\n",
    "            print(\"Fintune has done! Average Score is {0} / 1\".format(np.average(epo_score) / 100))\n",
    "            break\n",
    "    pass\n",
    "    print(\"Valid Model...\")\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad = False\n",
    "    valid_tmp = []\n",
    "    for i_batch, sample_batched in enumerate(finetune_te_dl[i_file]):\n",
    "        for mini_batch in range(sample_batched['X'].size()[0]):\n",
    "            x = var(sample_batched['X'][mini_batch]).cuda()\n",
    "            val = var(sample_batched['close'][mini_batch]).cuda()\n",
    "            updn, ans = net(x, val)\n",
    "\n",
    "            y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][0 + 6]]])).cuda()\n",
    "            y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + 0] - sample_batched['Y'][mini_batch][5 + 0 + 0]])))).view(1,1,-1).cuda()\n",
    "            score = w[0] * (50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3))\n",
    "            for i_sm in range(1, 5):\n",
    "                y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][i_sm + 6]]])).cuda()\n",
    "                y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + i_sm] - sample_batched['Y'][mini_batch][5 + 0 + i_sm]])))).view(1,1,-1).cuda()\n",
    "                score += w[i_sm] * (50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3))\n",
    "\n",
    "            valid_tmp.append(score.cpu().data.numpy()[0])\n",
    "        print(\"Batch#{0}, Score = {1} / 1\".format(i_batch, np.round(np.average(valid_tmp[-sample_batched['X'].size()[0] : ]), 6)))\n",
    "    pass\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad = True\n",
    "    print(\"Fintune again for predict next week...\")\n",
    "    epo_score = []\n",
    "    no_up = 0\n",
    "    max_va = -1e9\n",
    "    for epo in range(teEPOCH):\n",
    "        print(\"epoch#\", epo + 1)\n",
    "        scores = []\n",
    "        for i_batch, sample_batched in enumerate(finetune_te_dl[i_file]):\n",
    "            for mini_batch in range(sample_batched['X'].size()[0]):\n",
    "                x = var(sample_batched['X'][mini_batch]).cuda()\n",
    "                val = var(sample_batched['close'][mini_batch]).cuda()\n",
    "                updn, ans = net(x, val)\n",
    "                op.zero_grad()\n",
    "\n",
    "                y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][0 + 6]]])).cuda()\n",
    "                y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + 0] - sample_batched['Y'][mini_batch][5 + 0 + 0]])))).view(1,1,-1).cuda()\n",
    "                score = w[0] * (50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3))\n",
    "                loss = lf3((50 * ((y2 - torch.abs(ans[0] - y2)) / y2) + 50 * lf4(updn[0], y3)).view(1, -1), _100.view(1, -1))\n",
    "                for i_sm in range(1, 5):\n",
    "                    y2 = var(torch.FloatTensor([[sample_batched['Y'][mini_batch][i_sm + 6]]])).cuda()\n",
    "                    y3 = var(torch.FloatTensor(np.sign(np.array([sample_batched['Y'][mini_batch][5 + 1 + i_sm] - sample_batched['Y'][mini_batch][5 + 0 + i_sm]])))).view(1,1,-1).cuda()\n",
    "                    score += w[i_sm] * (50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3))\n",
    "                    loss += lf3((50 * ((y2 - torch.abs(ans[i_sm] - y2)) / y2) + 50 * lf4(updn[i_sm], y3)).view(1, -1), _100.view(1, -1))\n",
    "\n",
    "                loss.backward(retain_graph = True)\n",
    "                op.step()\n",
    "                scores.append(score.cpu().data.numpy()[0])\n",
    "                cuda.empty_cache()\n",
    "        epo_score.append(np.average(scores))\n",
    "        print(\"score\", epo_score[-1])\n",
    "        if epo_score[-1] > max_va:\n",
    "            no_up = 0\n",
    "            max_va = epo_score[-1]\n",
    "        else:\n",
    "            no_up += 1\n",
    "            \n",
    "        if no_up >= 3:\n",
    "            print(\"Fintune has done! Average Score is {0} / 1\".format(np.average(epo_score) / 100))\n",
    "            break\n",
    "    pass\n",
    "    print(\"Prepare to predict\")\n",
    "    raw = pd.read_csv(\"../TBrain/DataSet/final18_\"+str(date_list[-1])+\".csv\")\n",
    "    val = raw.values\n",
    "    thisweek = []\n",
    "    idx = 0\n",
    "    for i in range(1, len(val)):\n",
    "        if val[i][1] != val[idx][1]:\n",
    "            thisweek.append(val[i - 9:i])\n",
    "            idx = i\n",
    "    thisweek.append(val[len(val) - 9:])\n",
    "    thisweek2 = []\n",
    "    for i in range(len(thisweek)):\n",
    "        tmp = []\n",
    "        for ii in range(len(thisweek[i])):\n",
    "            tmp.append(thisweek[i][ii][13:])\n",
    "        thisweek2.append(tmp)\n",
    "\n",
    "    x = var(torch.FloatTensor(thisweek2[i_file])).view(1, 9, -1).cuda()\n",
    "    val = var(torch.FloatTensor([thisweek[i_file][-1][7]])).cuda()\n",
    "    updn, ans = net(x, val)\n",
    "\n",
    "    res = []\n",
    "    res.append(code_uq[i_file])\n",
    "    for ans, ud in zip(ans, updn):\n",
    "        res.append(ud.view(-1).cpu().data.numpy()[0])\n",
    "        res.append(ans.view(-1).cpu().data.numpy()[0])\n",
    "    Result.append(res)\n",
    "    torch.save(net.state_dict(), \"./cr2_final_{0}_{1}.pth\".format(date_list[-1], code_uq[i_file]))\n",
    "    cuda.empty_cache()\n",
    "    print(\"Result:\", res)\n",
    "\n",
    "result = pd.DataFrame(Result, columns=[\"ETFid\",\"Mon_ud\",\"Mon_cprice\",\"Tue_ud\",\"Tue_cprice\", \"Wed_ud\",\"Wed_cprice\",\"Thu_ud\",\"Thu_cprice\",\"Fri_ud\",\"Fri_cprice\"])\n",
    "result.to_csv(\"./cr2_result_\"+str(date_list[-1])+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls |grep cr2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
